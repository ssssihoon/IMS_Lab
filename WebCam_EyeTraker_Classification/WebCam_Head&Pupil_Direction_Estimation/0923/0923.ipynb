{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db19df2-8d28-4898-adf0-7d77b7bd974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_5\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(1, 64, 6, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 107\u001b[0m\n\u001b[0;32m    103\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39m[cnn_right\u001b[38;5;241m.\u001b[39minput, cnn_left\u001b[38;5;241m.\u001b[39minput], outputs\u001b[38;5;241m=\u001b[39mfinal_output)\n\u001b[0;32m    105\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 107\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_images_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_images_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_images_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_images_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m fold_train_accuracies\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    113\u001b[0m fold_val_accuracies\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\.conda\\envs\\cam\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\cam\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_5\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(1, 64, 6, 3)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from keras import layers, Model, Input\n",
    "from keras.models import load_model\n",
    "\n",
    "folder_path = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\Pupil\\crop_img\"\n",
    "results = pd.read_excel(\"results.xlsx\", header=None)\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, '*.jpg'))\n",
    "\n",
    "right_images = [file for file in files if 'right' in os.path.basename(file).lower()]\n",
    "left_images = [file for file in files if 'left' in os.path.basename(file).lower()]\n",
    "4\n",
    "def load_and_preprocess_image(image_path, target_size=(64, 6)):\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "right_images = np.array([load_and_preprocess_image(img_path) for img_path in right_images])\n",
    "left_images = np.array([load_and_preprocess_image(img_path) for img_path in left_images])\n",
    "\n",
    "labels = results[0].values\n",
    "num_classes = len(np.unique(labels))\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(16, kernel_size=(7, 7), activation='mish', padding='same', strides=(2, 2))(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(16, kernel_size=(5, 5), activation='mish', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), activation='mish', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), activation='mish', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)    \n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), activation='mish', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, kernel_size=(2, 2), activation='mish', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_train_accuracies = []\n",
    "fold_val_accuracies = []\n",
    "\n",
    "# 모델 저장\n",
    "model_save_folder = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\models\"\n",
    "if not os.path.exists(model_save_folder):\n",
    "    os.makedirs(model_save_folder)\n",
    "\n",
    "# csv파일로 저장\n",
    "csv_save_folder = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\predictions\"\n",
    "if not os.path.exists(csv_save_folder):\n",
    "    os.makedirs(csv_save_folder)\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(right_images)):\n",
    "    right_images_train, right_images_val = right_images[train_index], right_images[val_index]\n",
    "    left_images_train, left_images_val = left_images[train_index], left_images[val_index]\n",
    "    labels_train, labels_val = labels[train_index], labels[val_index]\n",
    "\n",
    "    cnn_right = create_cnn_model((64, 64, 3))\n",
    "    cnn_left = create_cnn_model((64, 64, 3))\n",
    "\n",
    "    # Flatten layers\n",
    "    right_flatten = layers.Flatten()(cnn_right.output)\n",
    "    left_flatten = layers.Flatten()(cnn_left.output)\n",
    "\n",
    "    # Concatenate\n",
    "    combined = layers.Concatenate()([right_flatten, left_flatten])\n",
    "\n",
    "    fc_output = layers.Dense(128, activation='mish')(combined)\n",
    "    fc_output = layers.BatchNormalization()(fc_output)\n",
    "    fc_output = layers.Dropout(0.5)(fc_output)\n",
    "    \n",
    "    final_output = layers.Dense(num_classes, activation='softmax')(fc_output)\n",
    "\n",
    "    model = Model(inputs=[cnn_right.input, cnn_left.input], outputs=final_output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit([right_images_train, left_images_train], labels_train,\n",
    "                        epochs=300,\n",
    "                        batch_size=1, \n",
    "                        validation_data=([right_images_val, left_images_val], labels_val))\n",
    "\n",
    "    fold_train_accuracies.append(history.history['accuracy'][-1])\n",
    "    fold_val_accuracies.append(history.history['val_accuracy'][-1])\n",
    "\n",
    "    print(f\"Fold {fold_idx+1} - Train Accuracy: {fold_train_accuracies[-1]}, Validation Accuracy: {fold_val_accuracies[-1]}\")\n",
    "\n",
    "    model_save_path = os.path.join(model_save_folder, f\"fold_{fold_idx+1}_model.h5\")\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Fold {fold_idx+1} 모델 저장됨: {model_save_path}\")\n",
    "\n",
    "    predictions = model.predict([right_images_val, left_images_val])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    actual_classes = np.argmax(labels_val, axis=1)\n",
    "\n",
    "    right_image_files_val = [os.path.basename(files[idx]) for idx in val_index]\n",
    "    left_image_files_val = [os.path.basename(files[idx]) for idx in val_index]\n",
    "\n",
    "    # CSV에 저장할 데이터\n",
    "    data = {\n",
    "        'Right Image': right_image_files_val,\n",
    "        'Left Image': left_image_files_val,\n",
    "        'Actual Class': actual_classes,\n",
    "        'Predicted Class': predicted_classes\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # CSV 파일 저장\n",
    "    csv_save_path = os.path.join(csv_save_folder, f\"fold_{fold_idx+1}_predictions.csv\")\n",
    "    df.to_csv(csv_save_path, index=False)\n",
    "    print(f\"Fold {fold_idx+1} 예측 결과 저장됨: {csv_save_path}\")\n",
    "\n",
    "avg_train_accuracy = np.mean(fold_train_accuracies)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "\n",
    "print(f'Average Train Accuracy: {avg_train_accuracy}')\n",
    "print(f'Average Validation Accuracy: {avg_val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7b525-1822-4515-973e-b4dd9066e94f",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59554c-e470-45db-ae3b-eef344e94734",
   "metadata": {},
   "source": [
    "# cunstom vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66437539-5b67-4513-9ff3-1b500234acef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 878ms/step - accuracy: 0.5993 - loss: 1.0255 - val_accuracy: 0.2500 - val_loss: 6.1408\n",
      "Epoch 2/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 877ms/step - accuracy: 0.7734 - loss: 0.6596 - val_accuracy: 0.2486 - val_loss: 2.7736\n",
      "Epoch 3/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 877ms/step - accuracy: 0.7910 - loss: 0.6061 - val_accuracy: 0.1671 - val_loss: 9.5234\n",
      "Epoch 4/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 875ms/step - accuracy: 0.8007 - loss: 0.6068 - val_accuracy: 0.7214 - val_loss: 0.7792\n",
      "Epoch 5/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 881ms/step - accuracy: 0.8071 - loss: 0.5782 - val_accuracy: 0.7314 - val_loss: 0.5815\n",
      "Epoch 6/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 872ms/step - accuracy: 0.8343 - loss: 0.5113 - val_accuracy: 0.6600 - val_loss: 1.1153\n",
      "Epoch 7/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 871ms/step - accuracy: 0.8573 - loss: 0.4591 - val_accuracy: 0.9457 - val_loss: 0.1813\n",
      "Epoch 8/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 875ms/step - accuracy: 0.8325 - loss: 0.5266 - val_accuracy: 0.2386 - val_loss: 7.2929\n",
      "Epoch 9/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 875ms/step - accuracy: 0.8442 - loss: 0.4579 - val_accuracy: 0.8700 - val_loss: 0.3306\n",
      "Epoch 10/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 873ms/step - accuracy: 0.8363 - loss: 0.5377 - val_accuracy: 0.3057 - val_loss: 6.1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Accuracy: 0.8594420552253723, Validation Accuracy: 0.30571427941322327\n",
      "Fold 1 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\models\\fold_1_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step\n",
      "Fold 1 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\predictions\\fold_1_predictions.csv\n",
      "Epoch 1/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 898ms/step - accuracy: 0.6405 - loss: 0.9865 - val_accuracy: 0.3305 - val_loss: 1.6126\n",
      "Epoch 2/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 883ms/step - accuracy: 0.7755 - loss: 0.7030 - val_accuracy: 0.2189 - val_loss: 6.7486\n",
      "Epoch 3/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 891ms/step - accuracy: 0.8232 - loss: 0.5505 - val_accuracy: 0.1831 - val_loss: 18.9759\n",
      "Epoch 4/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 883ms/step - accuracy: 0.8396 - loss: 0.5002 - val_accuracy: 0.4034 - val_loss: 1.3671\n",
      "Epoch 5/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 881ms/step - accuracy: 0.8459 - loss: 0.5068 - val_accuracy: 0.9585 - val_loss: 0.1236\n",
      "Epoch 6/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 888ms/step - accuracy: 0.8630 - loss: 0.4385 - val_accuracy: 0.9771 - val_loss: 0.0812\n",
      "Epoch 7/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 888ms/step - accuracy: 0.8556 - loss: 0.4400 - val_accuracy: 0.3705 - val_loss: 1.9068\n",
      "Epoch 8/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 893ms/step - accuracy: 0.8243 - loss: 0.5339 - val_accuracy: 0.9828 - val_loss: 0.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 884ms/step - accuracy: 0.8710 - loss: 0.4103 - val_accuracy: 0.9614 - val_loss: 0.1289\n",
      "Epoch 10/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 881ms/step - accuracy: 0.8865 - loss: 0.3481 - val_accuracy: 0.9056 - val_loss: 13391998484480.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Train Accuracy: 0.8852341771125793, Validation Accuracy: 0.9055793881416321\n",
      "Fold 2 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\models\\fold_2_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step\n",
      "Fold 2 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\predictions\\fold_2_predictions.csv\n",
      "Epoch 1/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 863ms/step - accuracy: 0.6381 - loss: 0.9635 - val_accuracy: 0.1860 - val_loss: 28.0752\n",
      "Epoch 2/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 865ms/step - accuracy: 0.7570 - loss: 0.6906 - val_accuracy: 0.5279 - val_loss: 3.0494\n",
      "Epoch 3/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 864ms/step - accuracy: 0.7916 - loss: 0.5990 - val_accuracy: 0.8541 - val_loss: 0.4176\n",
      "Epoch 4/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 863ms/step - accuracy: 0.8084 - loss: 0.5985 - val_accuracy: 0.3333 - val_loss: 3.0312\n",
      "Epoch 5/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 861ms/step - accuracy: 0.8148 - loss: 0.5834 - val_accuracy: 0.5379 - val_loss: 1.7293\n",
      "Epoch 6/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 863ms/step - accuracy: 0.7967 - loss: 0.6196 - val_accuracy: 0.3763 - val_loss: 8.4044\n",
      "Epoch 7/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 867ms/step - accuracy: 0.7913 - loss: 0.6106 - val_accuracy: 0.4921 - val_loss: 3.3996\n",
      "Epoch 8/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 866ms/step - accuracy: 0.8040 - loss: 0.6410 - val_accuracy: 0.4435 - val_loss: 1.7125\n",
      "Epoch 9/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 869ms/step - accuracy: 0.8172 - loss: 0.5800 - val_accuracy: 0.1874 - val_loss: 10.2979\n",
      "Epoch 10/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 851ms/step - accuracy: 0.8209 - loss: 0.5354 - val_accuracy: 0.8298 - val_loss: 2001045159936.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Train Accuracy: 0.8076510429382324, Validation Accuracy: 0.8297567963600159\n",
      "Fold 3 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\models\\fold_3_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step\n",
      "Fold 3 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\predictions\\fold_3_predictions.csv\n",
      "Epoch 1/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 860ms/step - accuracy: 0.6277 - loss: 0.9952 - val_accuracy: 0.4120 - val_loss: 1.9106\n",
      "Epoch 2/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 869ms/step - accuracy: 0.7871 - loss: 0.6178 - val_accuracy: 0.2132 - val_loss: 47.6990\n",
      "Epoch 3/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 876ms/step - accuracy: 0.7995 - loss: 0.5981 - val_accuracy: 0.2132 - val_loss: 14.5215\n",
      "Epoch 4/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 880ms/step - accuracy: 0.8428 - loss: 0.5446 - val_accuracy: 0.2475 - val_loss: 11.2219\n",
      "Epoch 5/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 886ms/step - accuracy: 0.8328 - loss: 0.5479 - val_accuracy: 0.2132 - val_loss: 24.9965\n",
      "Epoch 6/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 882ms/step - accuracy: 0.8404 - loss: 0.5128 - val_accuracy: 0.2132 - val_loss: 15.3461\n",
      "Epoch 7/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 880ms/step - accuracy: 0.8406 - loss: 0.5256 - val_accuracy: 0.2132 - val_loss: 14.0716\n",
      "Epoch 8/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 877ms/step - accuracy: 0.8493 - loss: 0.4868 - val_accuracy: 0.2132 - val_loss: 18.3529\n",
      "Epoch 9/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 870ms/step - accuracy: 0.8367 - loss: 0.5546 - val_accuracy: 0.3906 - val_loss: 473989578752.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 882ms/step - accuracy: 0.8610 - loss: 0.4579 - val_accuracy: 0.7525 - val_loss: 0.6687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Train Accuracy: 0.8562746047973633, Validation Accuracy: 0.7525035738945007\n",
      "Fold 4 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\models\\fold_4_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step\n",
      "Fold 4 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\predictions\\fold_4_predictions.csv\n",
      "Epoch 1/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 923ms/step - accuracy: 0.6360 - loss: 0.9928 - val_accuracy: 0.1803 - val_loss: 9.6373\n",
      "Epoch 2/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 896ms/step - accuracy: 0.7861 - loss: 0.6364 - val_accuracy: 0.1803 - val_loss: 32.1241\n",
      "Epoch 3/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 900ms/step - accuracy: 0.8244 - loss: 0.5612 - val_accuracy: 0.1803 - val_loss: 26.7783\n",
      "Epoch 4/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 893ms/step - accuracy: 0.8109 - loss: 0.5811 - val_accuracy: 0.3476 - val_loss: 6.8653\n",
      "Epoch 5/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 897ms/step - accuracy: 0.8559 - loss: 0.4523 - val_accuracy: 0.4492 - val_loss: 17786509312.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 904ms/step - accuracy: 0.8451 - loss: 0.4786 - val_accuracy: 0.9528 - val_loss: 0.1837\n",
      "Epoch 7/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 898ms/step - accuracy: 0.8603 - loss: 0.4605 - val_accuracy: 0.9585 - val_loss: 0.1429\n",
      "Epoch 8/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 900ms/step - accuracy: 0.8606 - loss: 0.4156 - val_accuracy: 0.8970 - val_loss: 1705.1653\n",
      "Epoch 9/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 902ms/step - accuracy: 0.8750 - loss: 0.4151 - val_accuracy: 0.8970 - val_loss: 89417.8438\n",
      "Epoch 10/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 898ms/step - accuracy: 0.8878 - loss: 0.3803 - val_accuracy: 0.1803 - val_loss: 7.1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Train Accuracy: 0.8752234578132629, Validation Accuracy: 0.18025751411914825\n",
      "Fold 5 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\models\\fold_5_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step\n",
      "Fold 5 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\predictions\\fold_5_predictions.csv\n",
      "Average Train Accuracy: 0.856765067577362\n",
      "Average Validation Accuracy: 0.594762310385704\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from keras import layers, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def mish(inputs):\n",
    "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
    "\n",
    "# 데이터 로드 경로\n",
    "folder_path = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\Pupil\\crop_img\"\n",
    "results = pd.read_excel(\"results.xlsx\", header=None)\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, '*.jpg'))\n",
    "\n",
    "right_images = [file for file in files if 'right' in os.path.basename(file).lower()]\n",
    "left_images = [file for file in files if 'left' in os.path.basename(file).lower()]\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "# 이미지 배열로 변환\n",
    "right_images = np.array([load_and_preprocess_image(img_path) for img_path in right_images])\n",
    "left_images = np.array([load_and_preprocess_image(img_path) for img_path in left_images])\n",
    "\n",
    "# 레이블 처리\n",
    "labels = results[0].values\n",
    "num_classes = len(np.unique(labels))\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# 커스텀 VGG19 모델 생성\n",
    "def create_custom_vgg_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional Block 1\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation=mish)(inputs)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 4\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 5\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_train_accuracies = []\n",
    "fold_val_accuracies = []\n",
    "\n",
    "# 모델 저장 경로\n",
    "model_save_folder = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\models\"\n",
    "if not os.path.exists(model_save_folder):\n",
    "    os.makedirs(model_save_folder)\n",
    "\n",
    "# CSV 파일 저장 경로\n",
    "csv_save_folder = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\predictions\"\n",
    "if not os.path.exists(csv_save_folder):\n",
    "    os.makedirs(csv_save_folder)\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(right_images)):\n",
    "    right_images_train, right_images_val = right_images[train_index], right_images[val_index]\n",
    "    left_images_train, left_images_val = left_images[train_index], left_images[val_index]\n",
    "    labels_train, labels_val = labels[train_index], labels[val_index]\n",
    "\n",
    "    cnn_right = create_custom_vgg_model((128, 128, 3))\n",
    "    cnn_left = create_custom_vgg_model((128, 128, 3))\n",
    "\n",
    "    # Flatten layers\n",
    "    right_flatten = layers.Flatten()(cnn_right.output)\n",
    "    left_flatten = layers.Flatten()(cnn_left.output)\n",
    "\n",
    "    # Concatenate\n",
    "    combined = layers.Concatenate()([right_flatten, left_flatten])\n",
    "\n",
    "    fc_output = layers.Dense(128, activation=mish)(combined)\n",
    "    fc_output = layers.BatchNormalization()(fc_output)\n",
    "    fc_output = layers.Dropout(0.5)(fc_output)\n",
    "    \n",
    "    final_output = layers.Dense(num_classes, activation='softmax')(fc_output)\n",
    "\n",
    "    model = Model(inputs=[cnn_right.input, cnn_left.input], outputs=final_output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit([right_images_train, left_images_train], labels_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=4, \n",
    "                        validation_data=([right_images_val, left_images_val], labels_val))\n",
    "\n",
    "    fold_train_accuracies.append(history.history['accuracy'][-1])\n",
    "    fold_val_accuracies.append(history.history['val_accuracy'][-1])\n",
    "\n",
    "    print(f\"Fold {fold_idx+1} - Train Accuracy: {fold_train_accuracies[-1]}, Validation Accuracy: {fold_val_accuracies[-1]}\")\n",
    "\n",
    "    model_save_path = os.path.join(model_save_folder, f\"fold_{fold_idx+1}_model.h5\")\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Fold {fold_idx+1} 모델 저장됨: {model_save_path}\")\n",
    "\n",
    "    predictions = model.predict([right_images_val, left_images_val])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    actual_classes = np.argmax(labels_val, axis=1)\n",
    "\n",
    "    right_image_files_val = [os.path.basename(files[idx]) for idx in val_index]\n",
    "    left_image_files_val = [os.path.basename(files[idx]) for idx in val_index]\n",
    "\n",
    "    # CSV에 저장할 데이터\n",
    "    data = {\n",
    "        'Right Image': right_image_files_val,\n",
    "        'Left Image': left_image_files_val,\n",
    "        'Actual Class': actual_classes,\n",
    "        'Predicted Class': predicted_classes\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # CSV 파일 저장\n",
    "    csv_save_path = os.path.join(csv_save_folder, f\"fold_{fold_idx+1}_predictions.csv\")\n",
    "    df.to_csv(csv_save_path, index=False)\n",
    "    print(f\"Fold {fold_idx+1} 예측 결과 저장됨: {csv_save_path}\")\n",
    "\n",
    "avg_train_accuracy = np.mean(fold_train_accuracies)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "\n",
    "print(f'Average Train Accuracy: {avg_train_accuracy}')\n",
    "print(f'Average Validation Accuracy: {avg_val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce5533-b6c8-4634-87e5-50d14819f5fd",
   "metadata": {},
   "source": [
    "# 64X64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8955fb8-3aec-4fab-9c41-b6478d4a761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 660ms/step - accuracy: 0.3780 - loss: 1.4383 - val_accuracy: 0.2943 - val_loss: 9.0208\n",
      "Epoch 2/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.4545 - loss: 1.1563 - val_accuracy: 0.2386 - val_loss: 8.4108\n",
      "Epoch 3/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.5463 - loss: 1.0236 - val_accuracy: 0.2386 - val_loss: 30.0297\n",
      "Epoch 4/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 655ms/step - accuracy: 0.6060 - loss: 0.9094 - val_accuracy: 0.1671 - val_loss: 10.7762\n",
      "Epoch 5/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 648ms/step - accuracy: 0.7797 - loss: 0.6283 - val_accuracy: 0.2386 - val_loss: 8.8749\n",
      "Epoch 6/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.8314 - loss: 0.5226 - val_accuracy: 0.4386 - val_loss: 2.9719\n",
      "Epoch 7/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 650ms/step - accuracy: 0.8421 - loss: 0.4629 - val_accuracy: 0.3343 - val_loss: 2.8171\n",
      "Epoch 8/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.8722 - loss: 0.3984 - val_accuracy: 0.2386 - val_loss: 5.2258\n",
      "Epoch 9/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.8652 - loss: 0.3564 - val_accuracy: 0.3543 - val_loss: 3.8425\n",
      "Epoch 10/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 643ms/step - accuracy: 0.8900 - loss: 0.3525 - val_accuracy: 0.4414 - val_loss: 11.6734\n",
      "Epoch 11/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 644ms/step - accuracy: 0.8990 - loss: 0.3253 - val_accuracy: 0.6671 - val_loss: 1.0735\n",
      "Epoch 12/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.8739 - loss: 0.3650 - val_accuracy: 0.3929 - val_loss: 4.9826\n",
      "Epoch 13/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.9221 - loss: 0.2610 - val_accuracy: 0.9800 - val_loss: 0.1060\n",
      "Epoch 14/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 629ms/step - accuracy: 0.8920 - loss: 0.2868 - val_accuracy: 0.8643 - val_loss: 3178679500800.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 653ms/step - accuracy: 0.9361 - loss: 0.2104 - val_accuracy: 0.3571 - val_loss: 3.8638\n",
      "Epoch 16/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 644ms/step - accuracy: 0.9296 - loss: 0.2192 - val_accuracy: 0.3543 - val_loss: 3.6489\n",
      "Epoch 17/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.9379 - loss: 0.1727 - val_accuracy: 0.8757 - val_loss: 0.3766\n",
      "Epoch 18/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 643ms/step - accuracy: 0.9347 - loss: 0.2258 - val_accuracy: 0.9957 - val_loss: 0.0303\n",
      "Epoch 19/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 648ms/step - accuracy: 0.9559 - loss: 0.1388 - val_accuracy: 0.5943 - val_loss: 0.8911\n",
      "Epoch 20/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 652ms/step - accuracy: 0.9729 - loss: 0.0857 - val_accuracy: 0.9943 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.9635 - loss: 0.1428 - val_accuracy: 0.7957 - val_loss: 0.7883\n",
      "Epoch 22/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.9556 - loss: 0.1639 - val_accuracy: 0.9643 - val_loss: 0.1124\n",
      "Epoch 23/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.9636 - loss: 0.1159 - val_accuracy: 0.9929 - val_loss: 0.0235\n",
      "Epoch 24/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 650ms/step - accuracy: 0.9739 - loss: 0.0964 - val_accuracy: 0.9757 - val_loss: 0.0867\n",
      "Epoch 25/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.9789 - loss: 0.0897 - val_accuracy: 0.9986 - val_loss: 0.0077\n",
      "Epoch 26/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 652ms/step - accuracy: 0.9617 - loss: 0.1168 - val_accuracy: 0.9857 - val_loss: 0.0566\n",
      "Epoch 27/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.9829 - loss: 0.0766 - val_accuracy: 0.9514 - val_loss: 0.1213\n",
      "Epoch 28/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.9644 - loss: 0.1367 - val_accuracy: 0.9971 - val_loss: 0.0264\n",
      "Epoch 29/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.9825 - loss: 0.0603 - val_accuracy: 0.9914 - val_loss: 0.0198\n",
      "Epoch 30/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 653ms/step - accuracy: 0.9807 - loss: 0.0795 - val_accuracy: 0.9929 - val_loss: 0.0330\n",
      "Epoch 31/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 669ms/step - accuracy: 0.9619 - loss: 0.1101 - val_accuracy: 0.6129 - val_loss: 0.8098\n",
      "Epoch 32/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.9694 - loss: 0.1175 - val_accuracy: 0.9929 - val_loss: 0.0285\n",
      "Epoch 33/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 647ms/step - accuracy: 0.9853 - loss: 0.0536 - val_accuracy: 0.9857 - val_loss: 0.0769\n",
      "Epoch 34/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 645ms/step - accuracy: 0.9727 - loss: 0.0965 - val_accuracy: 0.9971 - val_loss: 0.0141\n",
      "Epoch 35/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 651ms/step - accuracy: 0.9799 - loss: 0.0884 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 36/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.9800 - loss: 0.0769 - val_accuracy: 0.9700 - val_loss: 0.0971\n",
      "Epoch 37/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.9770 - loss: 0.0753 - val_accuracy: 0.9929 - val_loss: 0.0386\n",
      "Epoch 38/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.9904 - loss: 0.0349 - val_accuracy: 0.9971 - val_loss: 0.0126\n",
      "Epoch 39/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.9949 - loss: 0.0242 - val_accuracy: 0.9914 - val_loss: 0.0510\n",
      "Epoch 40/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.9918 - loss: 0.0320 - val_accuracy: 0.9929 - val_loss: 0.0384\n",
      "Epoch 41/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 644ms/step - accuracy: 0.9856 - loss: 0.0598 - val_accuracy: 0.9914 - val_loss: 0.0419\n",
      "Epoch 42/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 653ms/step - accuracy: 0.9772 - loss: 0.0612 - val_accuracy: 0.9957 - val_loss: 0.0165\n",
      "Epoch 43/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 645ms/step - accuracy: 0.9882 - loss: 0.0580 - val_accuracy: 0.9957 - val_loss: 0.0082\n",
      "Epoch 44/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.9846 - loss: 0.0481 - val_accuracy: 0.9957 - val_loss: 0.0163\n",
      "Epoch 45/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.9959 - loss: 0.0177 - val_accuracy: 0.9957 - val_loss: 0.0152\n",
      "Epoch 46/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 627ms/step - accuracy: 0.9901 - loss: 0.0389 - val_accuracy: 0.9886 - val_loss: 0.0513\n",
      "Epoch 47/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.9870 - loss: 0.0587 - val_accuracy: 0.8629 - val_loss: 0.3540\n",
      "Epoch 48/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 655ms/step - accuracy: 0.9883 - loss: 0.0602 - val_accuracy: 0.7957 - val_loss: 0.8561\n",
      "Epoch 49/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 648ms/step - accuracy: 0.9794 - loss: 0.0780 - val_accuracy: 0.9986 - val_loss: 0.0053\n",
      "Epoch 50/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.9835 - loss: 0.0620 - val_accuracy: 0.1971 - val_loss: 1.6251\n",
      "Epoch 51/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 633ms/step - accuracy: 0.4353 - loss: 1.2032 - val_accuracy: 0.2386 - val_loss: 1.6089\n",
      "Epoch 52/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 633ms/step - accuracy: 0.9536 - loss: 0.1310 - val_accuracy: 0.2386 - val_loss: 1.6104\n",
      "Epoch 53/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.2164 - loss: 1.5984 - val_accuracy: 0.2386 - val_loss: 1.6068\n",
      "Epoch 54/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.2478 - loss: 1.5580 - val_accuracy: 0.1671 - val_loss: 1.6181\n",
      "Epoch 55/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 648ms/step - accuracy: 0.2543 - loss: 1.5667 - val_accuracy: 0.1671 - val_loss: 1.6192\n",
      "Epoch 56/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 641ms/step - accuracy: 0.1876 - loss: 1.6157 - val_accuracy: 0.1971 - val_loss: 1.6135\n",
      "Epoch 57/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.2085 - loss: 1.6094 - val_accuracy: 0.1671 - val_loss: 1.6136\n",
      "Epoch 58/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 630ms/step - accuracy: 0.2219 - loss: 1.6058 - val_accuracy: 0.2029 - val_loss: 1.6116\n",
      "Epoch 59/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 641ms/step - accuracy: 0.5648 - loss: 1.1591 - val_accuracy: 0.1943 - val_loss: 1.6437\n",
      "Epoch 60/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 647ms/step - accuracy: 0.9258 - loss: 0.2237 - val_accuracy: 0.2000 - val_loss: 1.5807\n",
      "Epoch 61/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.7734 - loss: 0.5286 - val_accuracy: 0.1943 - val_loss: 1.6183\n",
      "Epoch 62/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.2583 - loss: 1.5629 - val_accuracy: 0.1943 - val_loss: 1.6092\n",
      "Epoch 63/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.2100 - loss: 1.5970 - val_accuracy: 0.1671 - val_loss: 1.6152\n",
      "Epoch 64/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.2126 - loss: 1.6052 - val_accuracy: 0.1971 - val_loss: 1.6114\n",
      "Epoch 65/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 647ms/step - accuracy: 0.2125 - loss: 1.5926 - val_accuracy: 0.1943 - val_loss: 1.6131\n",
      "Epoch 66/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.2242 - loss: 1.5839 - val_accuracy: 0.2029 - val_loss: 1.6101\n",
      "Epoch 67/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.2120 - loss: 1.5891 - val_accuracy: 0.1671 - val_loss: 1.6110\n",
      "Epoch 68/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 648ms/step - accuracy: 0.2028 - loss: 1.6050 - val_accuracy: 0.1943 - val_loss: 1.6094\n",
      "Epoch 69/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.2222 - loss: 1.6055 - val_accuracy: 0.1671 - val_loss: 1.6161\n",
      "Epoch 70/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.2231 - loss: 1.6032 - val_accuracy: 0.1971 - val_loss: 1.6125\n",
      "Epoch 71/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 629ms/step - accuracy: 0.2184 - loss: 1.5855 - val_accuracy: 0.2029 - val_loss: 1.6122\n",
      "Epoch 72/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 641ms/step - accuracy: 0.2177 - loss: 1.5989 - val_accuracy: 0.2029 - val_loss: 1.6106\n",
      "Epoch 73/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.2344 - loss: 1.5763 - val_accuracy: 0.2029 - val_loss: 1.6127\n",
      "Epoch 74/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.2574 - loss: 1.5533 - val_accuracy: 0.1671 - val_loss: 1.6155\n",
      "Epoch 75/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 625ms/step - accuracy: 0.2041 - loss: 1.5839 - val_accuracy: 0.1971 - val_loss: 1.6111\n",
      "Epoch 76/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 608ms/step - accuracy: 0.1903 - loss: 1.6093 - val_accuracy: 0.1671 - val_loss: 1.6187\n",
      "Epoch 77/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.2101 - loss: 1.6072 - val_accuracy: 0.2029 - val_loss: 1.6151\n",
      "Epoch 78/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.2188 - loss: 1.6028 - val_accuracy: 0.1971 - val_loss: 1.6097\n",
      "Epoch 79/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 627ms/step - accuracy: 0.2136 - loss: 1.6073 - val_accuracy: 0.1671 - val_loss: 1.6171\n",
      "Epoch 80/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 644ms/step - accuracy: 0.2057 - loss: 1.6116 - val_accuracy: 0.1671 - val_loss: 1.6139\n",
      "Epoch 81/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 626ms/step - accuracy: 0.2430 - loss: 1.5563 - val_accuracy: 0.1671 - val_loss: 1.6169\n",
      "Epoch 82/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.1972 - loss: 1.6114 - val_accuracy: 0.1943 - val_loss: 1.6100\n",
      "Epoch 83/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.2023 - loss: 1.6098 - val_accuracy: 0.1971 - val_loss: 1.6170\n",
      "Epoch 84/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.2016 - loss: 1.6041 - val_accuracy: 0.2029 - val_loss: 1.6209\n",
      "Epoch 85/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.2211 - loss: 1.5848 - val_accuracy: 0.1671 - val_loss: 1.6135\n",
      "Epoch 86/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 629ms/step - accuracy: 0.2041 - loss: 1.6106 - val_accuracy: 0.1671 - val_loss: 1.6125\n",
      "Epoch 87/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.2006 - loss: 1.6109 - val_accuracy: 0.1671 - val_loss: 1.6149\n",
      "Epoch 88/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.1958 - loss: 1.6094 - val_accuracy: 0.1671 - val_loss: 1.6112\n",
      "Epoch 89/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.1958 - loss: 1.6113 - val_accuracy: 0.1971 - val_loss: 1.6175\n",
      "Epoch 90/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.1941 - loss: 1.6116 - val_accuracy: 0.1671 - val_loss: 1.6110\n",
      "Epoch 91/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.1932 - loss: 1.6113 - val_accuracy: 0.1671 - val_loss: 1.6107\n",
      "Epoch 92/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 633ms/step - accuracy: 0.2003 - loss: 1.6111 - val_accuracy: 0.1671 - val_loss: 1.6163\n",
      "Epoch 93/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.1928 - loss: 1.6118 - val_accuracy: 0.1671 - val_loss: 1.6181\n",
      "Epoch 94/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.2152 - loss: 1.6095 - val_accuracy: 0.1671 - val_loss: 1.6143\n",
      "Epoch 95/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.1887 - loss: 1.6116 - val_accuracy: 0.1671 - val_loss: 1.6120\n",
      "Epoch 96/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 630ms/step - accuracy: 0.1949 - loss: 1.6106 - val_accuracy: 0.1671 - val_loss: 1.6143\n",
      "Epoch 97/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.1929 - loss: 1.6113 - val_accuracy: 0.1671 - val_loss: 1.6173\n",
      "Epoch 98/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 633ms/step - accuracy: 0.2193 - loss: 1.6113 - val_accuracy: 0.1671 - val_loss: 1.6199\n",
      "Epoch 99/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.2101 - loss: 1.6082 - val_accuracy: 0.1943 - val_loss: 1.6149\n",
      "Epoch 100/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.2015 - loss: 1.6106 - val_accuracy: 0.1671 - val_loss: 1.6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Accuracy: 0.19742488861083984, Validation Accuracy: 0.167142853140831\n",
      "Fold 1 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_models\\fold_1_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 333ms/step\n",
      "Fold 1 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_predictions\\fold_1_predictions.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 653ms/step - accuracy: 0.4304 - loss: 1.3295 - val_accuracy: 0.1831 - val_loss: 16.1223\n",
      "Epoch 2/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.6497 - loss: 0.7870 - val_accuracy: 0.2146 - val_loss: 12.3826\n",
      "Epoch 3/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 667ms/step - accuracy: 0.7732 - loss: 0.6713 - val_accuracy: 0.1831 - val_loss: 15.0240\n",
      "Epoch 4/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.8068 - loss: 0.5215 - val_accuracy: 0.1831 - val_loss: 19.1490\n",
      "Epoch 5/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.8176 - loss: 0.5256 - val_accuracy: 0.2847 - val_loss: 6.4382\n",
      "Epoch 6/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.8577 - loss: 0.4247 - val_accuracy: 0.4878 - val_loss: 0.9388\n",
      "Epoch 7/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.8690 - loss: 0.3762 - val_accuracy: 0.2947 - val_loss: 11.5657\n",
      "Epoch 8/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.8793 - loss: 0.3971 - val_accuracy: 0.1888 - val_loss: 11.5646\n",
      "Epoch 9/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 664ms/step - accuracy: 0.8615 - loss: 0.4097 - val_accuracy: 0.7039 - val_loss: 0.5950\n",
      "Epoch 10/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.8640 - loss: 0.4249 - val_accuracy: 0.9557 - val_loss: 0.1875\n",
      "Epoch 11/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 652ms/step - accuracy: 0.8997 - loss: 0.3303 - val_accuracy: 0.1831 - val_loss: 20.2888\n",
      "Epoch 12/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.8817 - loss: 0.3634 - val_accuracy: 0.3362 - val_loss: 7.3508\n",
      "Epoch 13/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.9090 - loss: 0.2961 - val_accuracy: 0.6366 - val_loss: 1.1274\n",
      "Epoch 14/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.9176 - loss: 0.2978 - val_accuracy: 0.4192 - val_loss: 2.9928\n",
      "Epoch 15/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.9064 - loss: 0.2947 - val_accuracy: 0.9242 - val_loss: 0.2120\n",
      "Epoch 16/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.9168 - loss: 0.2666 - val_accuracy: 0.8441 - val_loss: 0.4501\n",
      "Epoch 17/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 645ms/step - accuracy: 0.9182 - loss: 0.2598 - val_accuracy: 0.1831 - val_loss: 35.1448\n",
      "Epoch 18/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 668ms/step - accuracy: 0.6756 - loss: 0.7816 - val_accuracy: 0.2146 - val_loss: 1.6097\n",
      "Epoch 19/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.2227 - loss: 1.5868 - val_accuracy: 0.1888 - val_loss: 1.6117\n",
      "Epoch 20/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 656ms/step - accuracy: 0.3013 - loss: 1.4866 - val_accuracy: 0.1831 - val_loss: 1.6121\n",
      "Epoch 21/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 667ms/step - accuracy: 0.2051 - loss: 1.5991 - val_accuracy: 0.1888 - val_loss: 1.6126\n",
      "Epoch 22/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.1945 - loss: 1.6145 - val_accuracy: 0.2074 - val_loss: 1.6101\n",
      "Epoch 23/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.1920 - loss: 1.6141 - val_accuracy: 0.2060 - val_loss: 1.6089\n",
      "Epoch 24/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 650ms/step - accuracy: 0.1843 - loss: 1.6136 - val_accuracy: 0.1831 - val_loss: 1.6140\n",
      "Epoch 25/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.1925 - loss: 1.6090 - val_accuracy: 0.2876 - val_loss: 1.5029\n",
      "Epoch 26/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 666ms/step - accuracy: 0.2274 - loss: 1.5613 - val_accuracy: 0.2074 - val_loss: 1.6097\n",
      "Epoch 27/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 667ms/step - accuracy: 0.7282 - loss: 0.6320 - val_accuracy: 0.1831 - val_loss: 1.6106\n",
      "Epoch 28/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 651ms/step - accuracy: 0.2111 - loss: 1.5905 - val_accuracy: 0.2146 - val_loss: 1.6095\n",
      "Epoch 29/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.3212 - loss: 1.4468 - val_accuracy: 0.2060 - val_loss: 1.6107\n",
      "Epoch 30/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.2293 - loss: 1.5711 - val_accuracy: 0.1831 - val_loss: 1.6103\n",
      "Epoch 31/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.9099 - loss: 0.2961 - val_accuracy: 0.2060 - val_loss: 1.6118\n",
      "Epoch 32/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.2692 - loss: 1.5432 - val_accuracy: 0.1831 - val_loss: 1.6118\n",
      "Epoch 33/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.2349 - loss: 1.5732 - val_accuracy: 0.1831 - val_loss: 1.6111\n",
      "Epoch 34/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 652ms/step - accuracy: 0.2180 - loss: 1.6032 - val_accuracy: 0.2060 - val_loss: 1.6104\n",
      "Epoch 35/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 667ms/step - accuracy: 0.2015 - loss: 1.6095 - val_accuracy: 0.2060 - val_loss: 1.6119\n",
      "Epoch 36/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.2047 - loss: 1.5962 - val_accuracy: 0.1831 - val_loss: 1.6132\n",
      "Epoch 37/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 654ms/step - accuracy: 0.2129 - loss: 1.5769 - val_accuracy: 0.1888 - val_loss: 1.6128\n",
      "Epoch 38/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.1930 - loss: 1.6082 - val_accuracy: 0.2060 - val_loss: 1.6120\n",
      "Epoch 39/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 669ms/step - accuracy: 0.1968 - loss: 1.6110 - val_accuracy: 0.1831 - val_loss: 1.6122\n",
      "Epoch 40/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.1831 - loss: 1.6104 - val_accuracy: 0.1831 - val_loss: 1.6123\n",
      "Epoch 41/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 671ms/step - accuracy: 0.1986 - loss: 1.6125 - val_accuracy: 0.2146 - val_loss: 1.6098\n",
      "Epoch 42/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.1900 - loss: 1.6117 - val_accuracy: 0.1831 - val_loss: 1.6103\n",
      "Epoch 43/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.2016 - loss: 1.6117 - val_accuracy: 0.1888 - val_loss: 1.6108\n",
      "Epoch 44/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 656ms/step - accuracy: 0.1873 - loss: 1.6102 - val_accuracy: 0.1888 - val_loss: 1.6111\n",
      "Epoch 45/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 667ms/step - accuracy: 0.2118 - loss: 1.6019 - val_accuracy: 0.1888 - val_loss: 1.6109\n",
      "Epoch 46/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.1986 - loss: 1.6088 - val_accuracy: 0.1831 - val_loss: 1.6098\n",
      "Epoch 47/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 667ms/step - accuracy: 0.2015 - loss: 1.6119 - val_accuracy: 0.1888 - val_loss: 1.6105\n",
      "Epoch 48/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.1814 - loss: 1.6124 - val_accuracy: 0.1831 - val_loss: 1.6100\n",
      "Epoch 49/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.1971 - loss: 1.6101 - val_accuracy: 0.2074 - val_loss: 1.6105\n",
      "Epoch 50/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.2036 - loss: 1.6105 - val_accuracy: 0.2146 - val_loss: 1.6091\n",
      "Epoch 51/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.2064 - loss: 1.6116 - val_accuracy: 0.1888 - val_loss: 1.6137\n",
      "Epoch 52/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 657ms/step - accuracy: 0.1862 - loss: 1.6121 - val_accuracy: 0.1888 - val_loss: 1.6117\n",
      "Epoch 53/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 657ms/step - accuracy: 0.2051 - loss: 1.6108 - val_accuracy: 0.2146 - val_loss: 1.6097\n",
      "Epoch 54/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 657ms/step - accuracy: 0.2078 - loss: 1.6104 - val_accuracy: 0.1888 - val_loss: 1.6109\n",
      "Epoch 55/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.1810 - loss: 1.6116 - val_accuracy: 0.1888 - val_loss: 1.6136\n",
      "Epoch 56/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 669ms/step - accuracy: 0.2026 - loss: 1.6113 - val_accuracy: 0.1831 - val_loss: 1.6105\n",
      "Epoch 57/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 670ms/step - accuracy: 0.2067 - loss: 1.6088 - val_accuracy: 0.2060 - val_loss: 1.6114\n",
      "Epoch 58/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.1879 - loss: 1.6102 - val_accuracy: 0.1831 - val_loss: 1.6108\n",
      "Epoch 59/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 670ms/step - accuracy: 0.1921 - loss: 1.6110 - val_accuracy: 0.2146 - val_loss: 1.6091\n",
      "Epoch 60/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.1922 - loss: 1.6112 - val_accuracy: 0.1888 - val_loss: 1.6117\n",
      "Epoch 61/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.2014 - loss: 1.6098 - val_accuracy: 0.2074 - val_loss: 1.6105\n",
      "Epoch 62/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 671ms/step - accuracy: 0.1994 - loss: 1.6117 - val_accuracy: 0.1888 - val_loss: 1.6120\n",
      "Epoch 63/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.2031 - loss: 1.6109 - val_accuracy: 0.2074 - val_loss: 1.6087\n",
      "Epoch 64/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 661ms/step - accuracy: 0.1980 - loss: 1.6114 - val_accuracy: 0.1831 - val_loss: 1.6109\n",
      "Epoch 65/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.1974 - loss: 1.6106 - val_accuracy: 0.1888 - val_loss: 1.6118\n",
      "Epoch 66/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 670ms/step - accuracy: 0.2170 - loss: 1.6099 - val_accuracy: 0.2146 - val_loss: 1.6092\n",
      "Epoch 67/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.2030 - loss: 1.6107 - val_accuracy: 0.2060 - val_loss: 1.6099\n",
      "Epoch 68/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.1923 - loss: 1.6108 - val_accuracy: 0.1831 - val_loss: 1.6099\n",
      "Epoch 69/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.2005 - loss: 1.6096 - val_accuracy: 0.1831 - val_loss: 1.6124\n",
      "Epoch 70/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.1867 - loss: 1.6114 - val_accuracy: 0.2060 - val_loss: 1.6095\n",
      "Epoch 71/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.1888 - loss: 1.6105 - val_accuracy: 0.1888 - val_loss: 1.6123\n",
      "Epoch 72/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 647ms/step - accuracy: 0.2100 - loss: 1.6107 - val_accuracy: 0.1831 - val_loss: 1.6110\n",
      "Epoch 73/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.1911 - loss: 1.6113 - val_accuracy: 0.1831 - val_loss: 1.6105\n",
      "Epoch 74/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.1976 - loss: 1.6102 - val_accuracy: 0.1831 - val_loss: 1.6097\n",
      "Epoch 75/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.1828 - loss: 1.6110 - val_accuracy: 0.1831 - val_loss: 1.6123\n",
      "Epoch 76/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.2122 - loss: 1.6105 - val_accuracy: 0.1888 - val_loss: 1.6104\n",
      "Epoch 77/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 666ms/step - accuracy: 0.2193 - loss: 1.6087 - val_accuracy: 0.2060 - val_loss: 1.6094\n",
      "Epoch 78/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 670ms/step - accuracy: 0.1900 - loss: 1.6108 - val_accuracy: 0.1831 - val_loss: 1.6116\n",
      "Epoch 79/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 663ms/step - accuracy: 0.1936 - loss: 1.6099 - val_accuracy: 0.2074 - val_loss: 1.6090\n",
      "Epoch 80/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.2035 - loss: 1.6100 - val_accuracy: 0.1888 - val_loss: 1.6112\n",
      "Epoch 81/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 657ms/step - accuracy: 0.2099 - loss: 1.6103 - val_accuracy: 0.1831 - val_loss: 1.6121\n",
      "Epoch 82/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.1987 - loss: 1.6099 - val_accuracy: 0.2074 - val_loss: 1.6096\n",
      "Epoch 83/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 658ms/step - accuracy: 0.1803 - loss: 1.6119 - val_accuracy: 0.1888 - val_loss: 1.6121\n",
      "Epoch 84/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.2047 - loss: 1.6108 - val_accuracy: 0.1831 - val_loss: 1.6097\n",
      "Epoch 85/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 668ms/step - accuracy: 0.1853 - loss: 1.6106 - val_accuracy: 0.1831 - val_loss: 1.6111\n",
      "Epoch 86/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 656ms/step - accuracy: 0.1989 - loss: 1.6108 - val_accuracy: 0.1831 - val_loss: 1.6109\n",
      "Epoch 87/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.2009 - loss: 1.6100 - val_accuracy: 0.1888 - val_loss: 1.6106\n",
      "Epoch 88/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.1994 - loss: 1.6100 - val_accuracy: 0.1831 - val_loss: 1.6100\n",
      "Epoch 89/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.1868 - loss: 1.6103 - val_accuracy: 0.1831 - val_loss: 1.6100\n",
      "Epoch 90/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 666ms/step - accuracy: 0.1874 - loss: 1.6105 - val_accuracy: 0.2060 - val_loss: 1.6099\n",
      "Epoch 91/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.1896 - loss: 1.6105 - val_accuracy: 0.2074 - val_loss: 1.6113\n",
      "Epoch 92/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 667ms/step - accuracy: 0.1749 - loss: 1.6112 - val_accuracy: 0.2074 - val_loss: 1.6094\n",
      "Epoch 93/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.1925 - loss: 1.6107 - val_accuracy: 0.1888 - val_loss: 1.6098\n",
      "Epoch 94/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 669ms/step - accuracy: 0.2069 - loss: 1.6099 - val_accuracy: 0.2074 - val_loss: 1.6098\n",
      "Epoch 95/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.1986 - loss: 1.6101 - val_accuracy: 0.1888 - val_loss: 1.6104\n",
      "Epoch 96/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 656ms/step - accuracy: 0.1909 - loss: 1.6101 - val_accuracy: 0.2074 - val_loss: 1.6107\n",
      "Epoch 97/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 666ms/step - accuracy: 0.1977 - loss: 1.6105 - val_accuracy: 0.1888 - val_loss: 1.6117\n",
      "Epoch 98/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 661ms/step - accuracy: 0.2145 - loss: 1.6102 - val_accuracy: 0.1831 - val_loss: 1.6108\n",
      "Epoch 99/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 673ms/step - accuracy: 0.2139 - loss: 1.6099 - val_accuracy: 0.1888 - val_loss: 1.6107\n",
      "Epoch 100/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 675ms/step - accuracy: 0.2082 - loss: 1.6097 - val_accuracy: 0.1888 - val_loss: 1.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Train Accuracy: 0.19377905130386353, Validation Accuracy: 0.18884120881557465\n",
      "Fold 2 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_models\\fold_2_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 334ms/step\n",
      "Fold 2 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_predictions\\fold_2_predictions.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 628ms/step - accuracy: 0.4561 - loss: 1.2682 - val_accuracy: 0.2003 - val_loss: 58.5103\n",
      "Epoch 2/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.6699 - loss: 0.7996 - val_accuracy: 0.1860 - val_loss: 34.5695\n",
      "Epoch 3/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 627ms/step - accuracy: 0.8118 - loss: 0.5388 - val_accuracy: 0.1874 - val_loss: 13.9908\n",
      "Epoch 4/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 630ms/step - accuracy: 0.8446 - loss: 0.4441 - val_accuracy: 0.2518 - val_loss: 11.4579\n",
      "Epoch 5/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.8387 - loss: 0.4640 - val_accuracy: 0.1874 - val_loss: 16.0567\n",
      "Epoch 6/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 630ms/step - accuracy: 0.8518 - loss: 0.4222 - val_accuracy: 0.5207 - val_loss: 1.1790\n",
      "Epoch 7/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 627ms/step - accuracy: 0.8458 - loss: 0.4527 - val_accuracy: 0.3476 - val_loss: 2.4648\n",
      "Epoch 8/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.8531 - loss: 0.4128 - val_accuracy: 0.5279 - val_loss: 1.1444\n",
      "Epoch 9/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 630ms/step - accuracy: 0.8792 - loss: 0.3640 - val_accuracy: 0.5951 - val_loss: 1.0718\n",
      "Epoch 10/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 626ms/step - accuracy: 0.8633 - loss: 0.3759 - val_accuracy: 0.1874 - val_loss: 11.4927\n",
      "Epoch 11/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.8829 - loss: 0.3677 - val_accuracy: 0.1874 - val_loss: 4.3408\n",
      "Epoch 12/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 630ms/step - accuracy: 0.8930 - loss: 0.3251 - val_accuracy: 0.7225 - val_loss: 0.6567\n",
      "Epoch 13/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.8871 - loss: 0.3683 - val_accuracy: 0.1874 - val_loss: 12.0658\n",
      "Epoch 14/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.9093 - loss: 0.3039 - val_accuracy: 0.4778 - val_loss: 2.5692\n",
      "Epoch 15/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 630ms/step - accuracy: 0.8726 - loss: 0.3821 - val_accuracy: 0.8541 - val_loss: 0.3793\n",
      "Epoch 16/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.8823 - loss: 0.3954 - val_accuracy: 0.4034 - val_loss: 2.4545\n",
      "Epoch 17/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.8595 - loss: 0.3854 - val_accuracy: 0.3133 - val_loss: 5.7117\n",
      "Epoch 18/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.8794 - loss: 0.3761 - val_accuracy: 0.9099 - val_loss: 0.2294\n",
      "Epoch 19/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.9028 - loss: 0.2924 - val_accuracy: 0.3891 - val_loss: 5.4873\n",
      "Epoch 20/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.8962 - loss: 0.3455 - val_accuracy: 0.6967 - val_loss: 0.6250\n",
      "Epoch 21/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.8927 - loss: 0.3163 - val_accuracy: 0.7196 - val_loss: 0.7605\n",
      "Epoch 22/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.9012 - loss: 0.3019 - val_accuracy: 0.3920 - val_loss: 3.1563\n",
      "Epoch 23/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 633ms/step - accuracy: 0.9019 - loss: 0.3245 - val_accuracy: 0.1888 - val_loss: 5.0956\n",
      "Epoch 24/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 627ms/step - accuracy: 0.8987 - loss: 0.3395 - val_accuracy: 0.1960 - val_loss: 5.8683\n",
      "Epoch 25/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 630ms/step - accuracy: 0.8909 - loss: 0.3201 - val_accuracy: 0.5694 - val_loss: 1.0854\n",
      "Epoch 26/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 633ms/step - accuracy: 0.8964 - loss: 0.3037 - val_accuracy: 0.1874 - val_loss: 8.2786\n",
      "Epoch 27/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.9010 - loss: 0.3199 - val_accuracy: 0.7754 - val_loss: 0.6786\n",
      "Epoch 28/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.9108 - loss: 0.2824 - val_accuracy: 0.1888 - val_loss: 8.2414\n",
      "Epoch 29/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 643ms/step - accuracy: 0.9282 - loss: 0.2281 - val_accuracy: 0.5951 - val_loss: 2.3933\n",
      "Epoch 30/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 652ms/step - accuracy: 0.9331 - loss: 0.2424 - val_accuracy: 0.6023 - val_loss: 0.8991\n",
      "Epoch 31/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.9585 - loss: 0.1698 - val_accuracy: 0.3934 - val_loss: 28149867872256.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 647ms/step - accuracy: 0.9476 - loss: 0.1947 - val_accuracy: 0.6624 - val_loss: 0.8387\n",
      "Epoch 33/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 650ms/step - accuracy: 0.9592 - loss: 0.1684 - val_accuracy: 0.9099 - val_loss: 0.2358\n",
      "Epoch 34/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 653ms/step - accuracy: 0.9499 - loss: 0.1708 - val_accuracy: 0.9213 - val_loss: 0.2428\n",
      "Epoch 35/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 650ms/step - accuracy: 0.9565 - loss: 0.1424 - val_accuracy: 0.5508 - val_loss: 3.3744\n",
      "Epoch 36/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 648ms/step - accuracy: 0.9532 - loss: 0.1591 - val_accuracy: 0.1860 - val_loss: 9.1076\n",
      "Epoch 37/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 651ms/step - accuracy: 0.9462 - loss: 0.2038 - val_accuracy: 0.2117 - val_loss: 1.6182\n",
      "Epoch 38/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 645ms/step - accuracy: 0.1952 - loss: 1.6436 - val_accuracy: 0.1917 - val_loss: 1.6118\n",
      "Epoch 39/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.2294 - loss: 1.5569 - val_accuracy: 0.1860 - val_loss: 1.6108\n",
      "Epoch 40/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 644ms/step - accuracy: 0.2630 - loss: 1.5152 - val_accuracy: 0.1860 - val_loss: 1.6127\n",
      "Epoch 41/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.2736 - loss: 1.5203 - val_accuracy: 0.1917 - val_loss: 1.6118\n",
      "Epoch 42/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 654ms/step - accuracy: 0.2756 - loss: 1.4781 - val_accuracy: 0.1860 - val_loss: 1.6115\n",
      "Epoch 43/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 650ms/step - accuracy: 0.2585 - loss: 1.5545 - val_accuracy: 0.2003 - val_loss: 1.6109\n",
      "Epoch 44/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 652ms/step - accuracy: 0.2800 - loss: 1.5175 - val_accuracy: 0.1917 - val_loss: 1.6117\n",
      "Epoch 45/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 655ms/step - accuracy: 0.2110 - loss: 1.6057 - val_accuracy: 0.2117 - val_loss: 1.6108\n",
      "Epoch 46/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 650ms/step - accuracy: 0.2545 - loss: 1.5433 - val_accuracy: 0.2103 - val_loss: 1.6096\n",
      "Epoch 47/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 645ms/step - accuracy: 0.2693 - loss: 1.5087 - val_accuracy: 0.2117 - val_loss: 1.6102\n",
      "Epoch 48/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 648ms/step - accuracy: 0.2858 - loss: 1.4810 - val_accuracy: 0.1860 - val_loss: 1.6098\n",
      "Epoch 49/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 650ms/step - accuracy: 0.6427 - loss: 0.7979 - val_accuracy: 0.1917 - val_loss: 1.6117\n",
      "Epoch 50/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 650ms/step - accuracy: 0.2516 - loss: 1.5422 - val_accuracy: 0.2117 - val_loss: 1.6095\n",
      "Epoch 51/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.3393 - loss: 1.3916 - val_accuracy: 0.2117 - val_loss: 1.6109\n",
      "Epoch 52/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 656ms/step - accuracy: 0.2423 - loss: 1.5592 - val_accuracy: 0.1860 - val_loss: 1.6102\n",
      "Epoch 53/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.3095 - loss: 1.4832 - val_accuracy: 0.1917 - val_loss: 1.6113\n",
      "Epoch 54/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.2529 - loss: 1.5185 - val_accuracy: 0.2117 - val_loss: 1.6113\n",
      "Epoch 55/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.2146 - loss: 1.5759 - val_accuracy: 0.1860 - val_loss: 1.6124\n",
      "Epoch 56/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.2893 - loss: 1.4873 - val_accuracy: 0.1860 - val_loss: 1.6103\n",
      "Epoch 57/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.4901 - loss: 1.0928 - val_accuracy: 0.1860 - val_loss: 1.6149\n",
      "Epoch 58/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 644ms/step - accuracy: 0.4650 - loss: 1.1241 - val_accuracy: 0.1860 - val_loss: 1.6099\n",
      "Epoch 59/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 655ms/step - accuracy: 0.2747 - loss: 1.5074 - val_accuracy: 0.1860 - val_loss: 1.6123\n",
      "Epoch 60/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 645ms/step - accuracy: 0.4141 - loss: 1.2427 - val_accuracy: 0.1917 - val_loss: 1.6124\n",
      "Epoch 61/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 650ms/step - accuracy: 0.2812 - loss: 1.4914 - val_accuracy: 0.2117 - val_loss: 1.6094\n",
      "Epoch 62/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.2735 - loss: 1.4584 - val_accuracy: 0.1860 - val_loss: 1.6132\n",
      "Epoch 63/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 652ms/step - accuracy: 0.2063 - loss: 1.5741 - val_accuracy: 0.2103 - val_loss: 1.6094\n",
      "Epoch 64/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 667ms/step - accuracy: 0.2528 - loss: 1.5561 - val_accuracy: 0.1917 - val_loss: 1.6102\n",
      "Epoch 65/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.2976 - loss: 1.4838 - val_accuracy: 0.1917 - val_loss: 1.6127\n",
      "Epoch 66/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.2852 - loss: 1.4954 - val_accuracy: 0.2003 - val_loss: 1.6121\n",
      "Epoch 67/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.2747 - loss: 1.5116 - val_accuracy: 0.1860 - val_loss: 1.6138\n",
      "Epoch 68/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 669ms/step - accuracy: 0.2483 - loss: 1.5320 - val_accuracy: 0.1860 - val_loss: 1.6103\n",
      "Epoch 69/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.2518 - loss: 1.5854 - val_accuracy: 0.1917 - val_loss: 1.6096\n",
      "Epoch 70/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.2531 - loss: 1.5503 - val_accuracy: 0.2117 - val_loss: 1.6101\n",
      "Epoch 71/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 666ms/step - accuracy: 0.2853 - loss: 1.4925 - val_accuracy: 0.2003 - val_loss: 1.6094\n",
      "Epoch 72/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.2440 - loss: 1.5670 - val_accuracy: 0.1917 - val_loss: 1.6101\n",
      "Epoch 73/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 667ms/step - accuracy: 0.1924 - loss: 1.6043 - val_accuracy: 0.1917 - val_loss: 1.6113\n",
      "Epoch 74/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 670ms/step - accuracy: 0.2211 - loss: 1.5981 - val_accuracy: 0.1860 - val_loss: 1.6103\n",
      "Epoch 75/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.2402 - loss: 1.5607 - val_accuracy: 0.1860 - val_loss: 1.6103\n",
      "Epoch 76/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 662ms/step - accuracy: 0.2346 - loss: 1.5542 - val_accuracy: 0.1860 - val_loss: 1.6125\n",
      "Epoch 77/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.1986 - loss: 1.6049 - val_accuracy: 0.2103 - val_loss: 1.6092\n",
      "Epoch 78/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.1977 - loss: 1.6105 - val_accuracy: 0.1917 - val_loss: 1.6128\n",
      "Epoch 79/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.2143 - loss: 1.6030 - val_accuracy: 0.1917 - val_loss: 1.6112\n",
      "Epoch 80/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 667ms/step - accuracy: 0.2346 - loss: 1.5879 - val_accuracy: 0.2003 - val_loss: 1.6103\n",
      "Epoch 81/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.1882 - loss: 1.6110 - val_accuracy: 0.1860 - val_loss: 1.6102\n",
      "Epoch 82/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.1967 - loss: 1.6101 - val_accuracy: 0.1917 - val_loss: 1.6104\n",
      "Epoch 83/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.1993 - loss: 1.6105 - val_accuracy: 0.2103 - val_loss: 1.6092\n",
      "Epoch 84/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 660ms/step - accuracy: 0.2086 - loss: 1.6107 - val_accuracy: 0.2003 - val_loss: 1.6129\n",
      "Epoch 85/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.1958 - loss: 1.6114 - val_accuracy: 0.1917 - val_loss: 1.6101\n",
      "Epoch 86/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 659ms/step - accuracy: 0.2015 - loss: 1.6099 - val_accuracy: 0.2003 - val_loss: 1.6097\n",
      "Epoch 87/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.1998 - loss: 1.6104 - val_accuracy: 0.1860 - val_loss: 1.6124\n",
      "Epoch 88/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.1979 - loss: 1.6112 - val_accuracy: 0.1917 - val_loss: 1.6106\n",
      "Epoch 89/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 669ms/step - accuracy: 0.1864 - loss: 1.6118 - val_accuracy: 0.1917 - val_loss: 1.6107\n",
      "Epoch 90/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 668ms/step - accuracy: 0.1977 - loss: 1.6101 - val_accuracy: 0.1860 - val_loss: 1.6115\n",
      "Epoch 91/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.2082 - loss: 1.6111 - val_accuracy: 0.2003 - val_loss: 1.6095\n",
      "Epoch 92/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 656ms/step - accuracy: 0.1811 - loss: 1.6117 - val_accuracy: 0.1860 - val_loss: 1.6109\n",
      "Epoch 93/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 664ms/step - accuracy: 0.2021 - loss: 1.6105 - val_accuracy: 0.1917 - val_loss: 1.6098\n",
      "Epoch 94/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.2057 - loss: 1.6113 - val_accuracy: 0.1917 - val_loss: 1.6110\n",
      "Epoch 95/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 664ms/step - accuracy: 0.1961 - loss: 1.6103 - val_accuracy: 0.2117 - val_loss: 1.6113\n",
      "Epoch 96/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 666ms/step - accuracy: 0.1979 - loss: 1.6104 - val_accuracy: 0.1917 - val_loss: 1.6113\n",
      "Epoch 97/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 665ms/step - accuracy: 0.1927 - loss: 1.6121 - val_accuracy: 0.1860 - val_loss: 1.6099\n",
      "Epoch 98/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 661ms/step - accuracy: 0.1967 - loss: 1.6102 - val_accuracy: 0.2003 - val_loss: 1.6103\n",
      "Epoch 99/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 664ms/step - accuracy: 0.1998 - loss: 1.6109 - val_accuracy: 0.2117 - val_loss: 1.6090\n",
      "Epoch 100/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 666ms/step - accuracy: 0.2008 - loss: 1.6101 - val_accuracy: 0.1917 - val_loss: 1.6098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Train Accuracy: 0.1941365748643875, Validation Accuracy: 0.19170242547988892\n",
      "Fold 3 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_models\\fold_3_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 334ms/step\n",
      "Fold 3 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_predictions\\fold_3_predictions.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 624ms/step - accuracy: 0.3936 - loss: 1.4606 - val_accuracy: 0.2175 - val_loss: 7.2987\n",
      "Epoch 2/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.5285 - loss: 1.0996 - val_accuracy: 0.2132 - val_loss: 40.1179\n",
      "Epoch 3/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 617ms/step - accuracy: 0.7318 - loss: 0.7186 - val_accuracy: 0.2132 - val_loss: 49.7194\n",
      "Epoch 4/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 616ms/step - accuracy: 0.8046 - loss: 0.5791 - val_accuracy: 0.2690 - val_loss: 3.5128\n",
      "Epoch 5/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.8885 - loss: 0.3429 - val_accuracy: 0.2132 - val_loss: 9.3578\n",
      "Epoch 6/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.9033 - loss: 0.3377 - val_accuracy: 0.6967 - val_loss: 1.0270\n",
      "Epoch 7/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9159 - loss: 0.2834 - val_accuracy: 0.3906 - val_loss: 15.2419\n",
      "Epoch 8/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.8961 - loss: 0.3213 - val_accuracy: 0.3190 - val_loss: 6.5591\n",
      "Epoch 9/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 627ms/step - accuracy: 0.9140 - loss: 0.2944 - val_accuracy: 0.2217 - val_loss: 4.4406\n",
      "Epoch 10/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.9467 - loss: 0.1903 - val_accuracy: 0.5708 - val_loss: 2.1358\n",
      "Epoch 11/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 616ms/step - accuracy: 0.9336 - loss: 0.2185 - val_accuracy: 0.8040 - val_loss: 0.5368\n",
      "Epoch 12/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9098 - loss: 0.2896 - val_accuracy: 0.8026 - val_loss: 0.6750\n",
      "Epoch 13/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 615ms/step - accuracy: 0.9367 - loss: 0.2168 - val_accuracy: 0.7883 - val_loss: 0.5959\n",
      "Epoch 14/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9502 - loss: 0.1698 - val_accuracy: 0.5536 - val_loss: 2.1277\n",
      "Epoch 15/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9593 - loss: 0.1491 - val_accuracy: 0.5036 - val_loss: 1.8381\n",
      "Epoch 16/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9453 - loss: 0.1755 - val_accuracy: 0.5522 - val_loss: 2.4582\n",
      "Epoch 17/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.9445 - loss: 0.1828 - val_accuracy: 0.5265 - val_loss: 187306328064.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 625ms/step - accuracy: 0.9482 - loss: 0.1642 - val_accuracy: 0.6624 - val_loss: 1.2857\n",
      "Epoch 19/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 627ms/step - accuracy: 0.9464 - loss: 0.2137 - val_accuracy: 0.9013 - val_loss: 0.2252\n",
      "Epoch 20/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 627ms/step - accuracy: 0.9509 - loss: 0.1436 - val_accuracy: 0.9585 - val_loss: 0.1261\n",
      "Epoch 21/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9555 - loss: 0.1547 - val_accuracy: 0.9771 - val_loss: 0.0766\n",
      "Epoch 22/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 615ms/step - accuracy: 0.9534 - loss: 0.1642 - val_accuracy: 0.2489 - val_loss: 4.3849\n",
      "Epoch 23/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 617ms/step - accuracy: 0.9563 - loss: 0.1600 - val_accuracy: 0.9714 - val_loss: 0.1000\n",
      "Epoch 24/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9540 - loss: 0.1508 - val_accuracy: 0.9757 - val_loss: 0.0766\n",
      "Epoch 25/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 616ms/step - accuracy: 0.9682 - loss: 0.1056 - val_accuracy: 0.5923 - val_loss: 2.2205\n",
      "Epoch 26/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9654 - loss: 0.1212 - val_accuracy: 0.6323 - val_loss: 2.1172\n",
      "Epoch 27/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.9873 - loss: 0.0557 - val_accuracy: 0.9857 - val_loss: 0.0377\n",
      "Epoch 28/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9827 - loss: 0.0656 - val_accuracy: 0.9914 - val_loss: 0.0382\n",
      "Epoch 29/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.9782 - loss: 0.0677 - val_accuracy: 0.7210 - val_loss: 0.7222\n",
      "Epoch 30/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.9739 - loss: 0.0825 - val_accuracy: 0.8298 - val_loss: 0.7980\n",
      "Epoch 31/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.9772 - loss: 0.0932 - val_accuracy: 0.9886 - val_loss: 0.0554\n",
      "Epoch 32/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9846 - loss: 0.0565 - val_accuracy: 0.9957 - val_loss: 0.0243\n",
      "Epoch 33/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.9769 - loss: 0.0975 - val_accuracy: 0.9814 - val_loss: 0.0450\n",
      "Epoch 34/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9852 - loss: 0.0543 - val_accuracy: 0.9928 - val_loss: 0.0216\n",
      "Epoch 35/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 621ms/step - accuracy: 0.9933 - loss: 0.0223 - val_accuracy: 0.7725 - val_loss: 0.4987\n",
      "Epoch 36/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9747 - loss: 0.0961 - val_accuracy: 0.9886 - val_loss: 0.0284\n",
      "Epoch 37/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.9920 - loss: 0.0309 - val_accuracy: 0.9485 - val_loss: 0.2608\n",
      "Epoch 38/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 626ms/step - accuracy: 0.9698 - loss: 0.1283 - val_accuracy: 0.9928 - val_loss: 0.0257\n",
      "Epoch 39/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9872 - loss: 0.0619 - val_accuracy: 0.9814 - val_loss: 0.0908\n",
      "Epoch 40/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9927 - loss: 0.0400 - val_accuracy: 0.9957 - val_loss: 0.0145\n",
      "Epoch 41/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9915 - loss: 0.0398 - val_accuracy: 0.9886 - val_loss: 0.0835\n",
      "Epoch 42/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9703 - loss: 0.1150 - val_accuracy: 0.9943 - val_loss: 0.0224\n",
      "Epoch 43/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 628ms/step - accuracy: 0.9962 - loss: 0.0167 - val_accuracy: 0.9943 - val_loss: 0.0338\n",
      "Epoch 44/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.9736 - loss: 0.1011 - val_accuracy: 0.8684 - val_loss: 0.3261\n",
      "Epoch 45/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9730 - loss: 0.1190 - val_accuracy: 0.9828 - val_loss: 0.0580\n",
      "Epoch 46/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 617ms/step - accuracy: 0.9902 - loss: 0.0382 - val_accuracy: 0.9971 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9951 - loss: 0.0184 - val_accuracy: 0.9456 - val_loss: 0.1889\n",
      "Epoch 48/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 626ms/step - accuracy: 0.9938 - loss: 0.0296 - val_accuracy: 0.9900 - val_loss: 0.0638\n",
      "Epoch 49/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 625ms/step - accuracy: 0.9908 - loss: 0.0486 - val_accuracy: 0.9785 - val_loss: 0.1443\n",
      "Epoch 50/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 627ms/step - accuracy: 0.9939 - loss: 0.0268 - val_accuracy: 0.9871 - val_loss: 0.0602\n",
      "Epoch 51/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9875 - loss: 0.0391 - val_accuracy: 0.9957 - val_loss: 0.0152\n",
      "Epoch 52/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 624ms/step - accuracy: 0.9838 - loss: 0.0764 - val_accuracy: 0.9971 - val_loss: 0.0120\n",
      "Epoch 53/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.9928 - loss: 0.0279 - val_accuracy: 0.9700 - val_loss: 25.5902\n",
      "Epoch 54/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9975 - loss: 0.0094 - val_accuracy: 0.9957 - val_loss: 0.0270\n",
      "Epoch 55/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.9910 - loss: 0.0387 - val_accuracy: 0.9900 - val_loss: 0.0401\n",
      "Epoch 56/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 632ms/step - accuracy: 0.9887 - loss: 0.0562 - val_accuracy: 0.9914 - val_loss: 0.0464\n",
      "Epoch 57/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 630ms/step - accuracy: 0.9894 - loss: 0.0276 - val_accuracy: 0.9971 - val_loss: 0.0151\n",
      "Epoch 58/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.9971 - val_loss: 0.0137\n",
      "Epoch 59/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 625ms/step - accuracy: 0.9968 - loss: 0.0093 - val_accuracy: 0.9986 - val_loss: 0.0066\n",
      "Epoch 60/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9871 - val_loss: 0.0947\n",
      "Epoch 61/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9930 - loss: 0.0220 - val_accuracy: 0.5994 - val_loss: 1.5485\n",
      "Epoch 62/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 629ms/step - accuracy: 0.9965 - loss: 0.0188 - val_accuracy: 0.9971 - val_loss: 0.0256\n",
      "Epoch 63/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.9918 - loss: 0.0328 - val_accuracy: 0.9943 - val_loss: 0.0627\n",
      "Epoch 64/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.9885 - loss: 0.0485 - val_accuracy: 0.9971 - val_loss: 0.0160\n",
      "Epoch 65/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.9949 - loss: 0.0245 - val_accuracy: 0.9900 - val_loss: 0.0395\n",
      "Epoch 66/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.9970 - loss: 0.0151 - val_accuracy: 0.9971 - val_loss: 0.0161\n",
      "Epoch 67/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.9958 - loss: 0.0180 - val_accuracy: 0.9971 - val_loss: 0.0233\n",
      "Epoch 68/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.9963 - loss: 0.0180 - val_accuracy: 0.9914 - val_loss: 0.0265\n",
      "Epoch 69/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.9998 - loss: 0.0040 - val_accuracy: 0.9928 - val_loss: 0.0365\n",
      "Epoch 70/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 632ms/step - accuracy: 0.9919 - loss: 0.0325 - val_accuracy: 0.9986 - val_loss: 0.0058\n",
      "Epoch 71/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 630ms/step - accuracy: 0.9959 - loss: 0.0137 - val_accuracy: 0.9900 - val_loss: 0.0808\n",
      "Epoch 72/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.9943 - loss: 0.0203 - val_accuracy: 0.9986 - val_loss: 0.0032\n",
      "Epoch 73/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9944 - loss: 0.0197 - val_accuracy: 0.9971 - val_loss: 0.0141\n",
      "Epoch 74/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 615ms/step - accuracy: 0.9907 - loss: 0.0539 - val_accuracy: 0.9928 - val_loss: 0.0457\n",
      "Epoch 75/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9962 - loss: 0.0108 - val_accuracy: 0.9957 - val_loss: 0.0428\n",
      "Epoch 76/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.9961 - loss: 0.0161 - val_accuracy: 0.9943 - val_loss: 0.0392\n",
      "Epoch 77/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9963 - loss: 0.0167 - val_accuracy: 0.9957 - val_loss: 0.0112\n",
      "Epoch 78/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.9971 - val_loss: 0.0241\n",
      "Epoch 79/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 622ms/step - accuracy: 0.9927 - loss: 0.0467 - val_accuracy: 0.7124 - val_loss: 0.4655\n",
      "Epoch 80/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.9962 - loss: 0.0137 - val_accuracy: 0.9971 - val_loss: 0.0149\n",
      "Epoch 81/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.9919 - loss: 0.0403 - val_accuracy: 0.9943 - val_loss: 0.0933\n",
      "Epoch 82/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.7200 - loss: 0.5987 - val_accuracy: 0.1989 - val_loss: 1.6238\n",
      "Epoch 83/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.2381 - loss: 1.5806 - val_accuracy: 0.2017 - val_loss: 1.6124\n",
      "Epoch 84/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.2169 - loss: 1.5939 - val_accuracy: 0.1845 - val_loss: 1.6119\n",
      "Epoch 85/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.2259 - loss: 1.6067 - val_accuracy: 0.1845 - val_loss: 1.6111\n",
      "Epoch 86/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.2218 - loss: 1.6006 - val_accuracy: 0.1845 - val_loss: 1.6119\n",
      "Epoch 87/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 616ms/step - accuracy: 0.2255 - loss: 1.6002 - val_accuracy: 0.2017 - val_loss: 1.6096\n",
      "Epoch 88/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.2274 - loss: 1.5822 - val_accuracy: 0.1845 - val_loss: 1.6158\n",
      "Epoch 89/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.2228 - loss: 1.5881 - val_accuracy: 0.1845 - val_loss: 1.6119\n",
      "Epoch 90/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.2082 - loss: 1.6112 - val_accuracy: 0.2017 - val_loss: 1.6116\n",
      "Epoch 91/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.2184 - loss: 1.6051 - val_accuracy: 0.1845 - val_loss: 1.6109\n",
      "Epoch 92/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.2354 - loss: 1.5814 - val_accuracy: 0.1845 - val_loss: 1.6152\n",
      "Epoch 93/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 613ms/step - accuracy: 0.1984 - loss: 1.5921 - val_accuracy: 0.2132 - val_loss: 1.6096\n",
      "Epoch 94/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.2039 - loss: 1.6144 - val_accuracy: 0.1845 - val_loss: 1.6111\n",
      "Epoch 95/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.1965 - loss: 1.6073 - val_accuracy: 0.2017 - val_loss: 1.6116\n",
      "Epoch 96/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.2016 - loss: 1.6082 - val_accuracy: 0.1989 - val_loss: 1.6098\n",
      "Epoch 97/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.2257 - loss: 1.5812 - val_accuracy: 0.1845 - val_loss: 1.6135\n",
      "Epoch 98/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.1942 - loss: 1.6124 - val_accuracy: 0.2132 - val_loss: 1.6094\n",
      "Epoch 99/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 625ms/step - accuracy: 0.1998 - loss: 1.6123 - val_accuracy: 0.1845 - val_loss: 1.6108\n",
      "Epoch 100/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.2143 - loss: 1.6085 - val_accuracy: 0.1845 - val_loss: 1.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Train Accuracy: 0.21558813750743866, Validation Accuracy: 0.18454936146736145\n",
      "Fold 4 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_models\\fold_4_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 334ms/step\n",
      "Fold 4 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_predictions\\fold_4_predictions.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 619ms/step - accuracy: 0.4624 - loss: 1.3053 - val_accuracy: 0.1803 - val_loss: 24.7654\n",
      "Epoch 2/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.6899 - loss: 0.8051 - val_accuracy: 0.2089 - val_loss: 8016137216.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.7315 - loss: 0.7080 - val_accuracy: 0.2089 - val_loss: 50.6185\n",
      "Epoch 4/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.8415 - loss: 0.5043 - val_accuracy: 0.1788 - val_loss: 36.7182\n",
      "Epoch 5/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.8551 - loss: 0.4165 - val_accuracy: 0.1803 - val_loss: 36.0820\n",
      "Epoch 6/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.8618 - loss: 0.4276 - val_accuracy: 0.1803 - val_loss: 31.4514\n",
      "Epoch 7/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.8909 - loss: 0.3607 - val_accuracy: 0.6867 - val_loss: 0.7257\n",
      "Epoch 8/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 629ms/step - accuracy: 0.8654 - loss: 0.3858 - val_accuracy: 0.9542 - val_loss: 0.2051\n",
      "Epoch 9/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.8689 - loss: 0.3836 - val_accuracy: 0.2246 - val_loss: 18.4402\n",
      "Epoch 10/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 616ms/step - accuracy: 0.8891 - loss: 0.3565 - val_accuracy: 0.2403 - val_loss: 18.9997\n",
      "Epoch 11/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.8707 - loss: 0.4095 - val_accuracy: 0.1803 - val_loss: 18.8878\n",
      "Epoch 12/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.8618 - loss: 0.4388 - val_accuracy: 0.6166 - val_loss: 0.8896\n",
      "Epoch 13/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.8962 - loss: 0.2999 - val_accuracy: 0.9413 - val_loss: 0.2142\n",
      "Epoch 14/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.8977 - loss: 0.3340 - val_accuracy: 0.3591 - val_loss: 5.2707\n",
      "Epoch 15/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.8982 - loss: 0.3234 - val_accuracy: 0.3605 - val_loss: 10.8163\n",
      "Epoch 16/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.8809 - loss: 0.3151 - val_accuracy: 0.1845 - val_loss: 4.4979\n",
      "Epoch 17/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9009 - loss: 0.3203 - val_accuracy: 0.9585 - val_loss: 0.1738\n",
      "Epoch 18/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9133 - loss: 0.2959 - val_accuracy: 0.9800 - val_loss: 0.0890\n",
      "Epoch 19/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9156 - loss: 0.2955 - val_accuracy: 0.4235 - val_loss: 11.8235\n",
      "Epoch 20/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 618ms/step - accuracy: 0.9242 - loss: 0.2440 - val_accuracy: 0.9714 - val_loss: 0.1149\n",
      "Epoch 21/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.8656 - loss: 0.3755 - val_accuracy: 0.6266 - val_loss: 2.7011\n",
      "Epoch 22/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.8750 - loss: 0.3797 - val_accuracy: 0.1803 - val_loss: 22.1136\n",
      "Epoch 23/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9026 - loss: 0.2979 - val_accuracy: 0.9857 - val_loss: 0.0956\n",
      "Epoch 24/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 619ms/step - accuracy: 0.9158 - loss: 0.2706 - val_accuracy: 0.3333 - val_loss: 2.6153\n",
      "Epoch 25/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.9038 - loss: 0.2804 - val_accuracy: 0.7697 - val_loss: 0.6005\n",
      "Epoch 26/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 621ms/step - accuracy: 0.9035 - loss: 0.2817 - val_accuracy: 0.1803 - val_loss: 29.1194\n",
      "Epoch 27/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.8887 - loss: 0.3551 - val_accuracy: 0.4134 - val_loss: 9.9910\n",
      "Epoch 28/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 620ms/step - accuracy: 0.8990 - loss: 0.3219 - val_accuracy: 0.7139 - val_loss: 0.7534\n",
      "Epoch 29/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 625ms/step - accuracy: 0.8873 - loss: 0.3476 - val_accuracy: 0.4292 - val_loss: 1.9795\n",
      "Epoch 30/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.9231 - loss: 0.2776 - val_accuracy: 0.8369 - val_loss: 0.3933\n",
      "Epoch 31/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 623ms/step - accuracy: 0.9196 - loss: 0.2775 - val_accuracy: 0.7482 - val_loss: 0.6343\n",
      "Epoch 32/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 619ms/step - accuracy: 0.9176 - loss: 0.2494 - val_accuracy: 0.4149 - val_loss: 8.8754\n",
      "Epoch 33/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 624ms/step - accuracy: 0.9177 - loss: 0.2617 - val_accuracy: 0.2375 - val_loss: 8.5519\n",
      "Epoch 34/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 626ms/step - accuracy: 0.8935 - loss: 0.3432 - val_accuracy: 0.9943 - val_loss: 0.0632\n",
      "Epoch 35/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.9208 - loss: 0.2343 - val_accuracy: 0.4034 - val_loss: 2.4727\n",
      "Epoch 36/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.8969 - loss: 0.3093 - val_accuracy: 0.1803 - val_loss: 28.3685\n",
      "Epoch 37/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.9196 - loss: 0.2589 - val_accuracy: 0.6009 - val_loss: 0.9257\n",
      "Epoch 38/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.9301 - loss: 0.2146 - val_accuracy: 0.9514 - val_loss: 0.1874\n",
      "Epoch 39/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.9242 - loss: 0.2269 - val_accuracy: 0.9900 - val_loss: 0.0454\n",
      "Epoch 40/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.9410 - loss: 0.2100 - val_accuracy: 0.1888 - val_loss: 4.8372\n",
      "Epoch 41/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.9364 - loss: 0.2069 - val_accuracy: 0.1803 - val_loss: 99.6349\n",
      "Epoch 42/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 632ms/step - accuracy: 0.7117 - loss: 0.6780 - val_accuracy: 0.1803 - val_loss: 1.6192\n",
      "Epoch 43/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 630ms/step - accuracy: 0.1952 - loss: 1.6490 - val_accuracy: 0.2246 - val_loss: 1.6089\n",
      "Epoch 44/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.2079 - loss: 1.5993 - val_accuracy: 0.1803 - val_loss: 1.6184\n",
      "Epoch 45/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 641ms/step - accuracy: 0.2294 - loss: 1.5532 - val_accuracy: 0.1803 - val_loss: 1.6187\n",
      "Epoch 46/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 631ms/step - accuracy: 0.8297 - loss: 0.4462 - val_accuracy: 0.1803 - val_loss: 1.6155\n",
      "Epoch 47/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.3356 - loss: 1.3786 - val_accuracy: 0.1831 - val_loss: 1.6163\n",
      "Epoch 48/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.2848 - loss: 1.4745 - val_accuracy: 0.2089 - val_loss: 1.6116\n",
      "Epoch 49/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.3366 - loss: 1.3902 - val_accuracy: 0.2089 - val_loss: 1.6138\n",
      "Epoch 50/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.4460 - loss: 1.2075 - val_accuracy: 0.1803 - val_loss: 1.6206\n",
      "Epoch 51/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 634ms/step - accuracy: 0.7167 - loss: 0.6407 - val_accuracy: 0.1803 - val_loss: 1.6151\n",
      "Epoch 52/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 629ms/step - accuracy: 0.8931 - loss: 0.2929 - val_accuracy: 0.1831 - val_loss: 1.6154\n",
      "Epoch 53/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 632ms/step - accuracy: 0.3243 - loss: 1.4344 - val_accuracy: 0.1831 - val_loss: 1.6116\n",
      "Epoch 54/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 632ms/step - accuracy: 0.7006 - loss: 0.7068 - val_accuracy: 0.2246 - val_loss: 1.6077\n",
      "Epoch 55/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.5293 - loss: 0.9870 - val_accuracy: 0.1831 - val_loss: 1.6151\n",
      "Epoch 56/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 649ms/step - accuracy: 0.5321 - loss: 1.0435 - val_accuracy: 0.2031 - val_loss: 1.6123\n",
      "Epoch 57/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 646ms/step - accuracy: 0.3699 - loss: 1.3538 - val_accuracy: 0.1803 - val_loss: 1.6188\n",
      "Epoch 58/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.6470 - loss: 0.7735 - val_accuracy: 0.2089 - val_loss: 1.6103\n",
      "Epoch 59/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.9323 - loss: 0.2189 - val_accuracy: 0.2089 - val_loss: 1.6117\n",
      "Epoch 60/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 643ms/step - accuracy: 0.8999 - loss: 0.3031 - val_accuracy: 0.2089 - val_loss: 1.6129\n",
      "Epoch 61/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.3152 - loss: 1.4751 - val_accuracy: 0.3634 - val_loss: 1.4156\n",
      "Epoch 62/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.6168 - loss: 0.8453 - val_accuracy: 0.1831 - val_loss: 1.6196\n",
      "Epoch 63/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.3982 - loss: 1.2764 - val_accuracy: 0.2031 - val_loss: 1.6105\n",
      "Epoch 64/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 641ms/step - accuracy: 0.2308 - loss: 1.5708 - val_accuracy: 0.1831 - val_loss: 1.6134\n",
      "Epoch 65/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.3307 - loss: 1.4461 - val_accuracy: 0.1831 - val_loss: 1.6144\n",
      "Epoch 66/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 632ms/step - accuracy: 0.2520 - loss: 1.5452 - val_accuracy: 0.1803 - val_loss: 1.6130\n",
      "Epoch 67/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.3025 - loss: 1.4837 - val_accuracy: 0.1831 - val_loss: 1.6128\n",
      "Epoch 68/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.2903 - loss: 1.4538 - val_accuracy: 0.2089 - val_loss: 1.6106\n",
      "Epoch 69/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.2698 - loss: 1.5073 - val_accuracy: 0.2089 - val_loss: 1.6123\n",
      "Epoch 70/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.3287 - loss: 1.4519 - val_accuracy: 0.1831 - val_loss: 1.6129\n",
      "Epoch 71/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.2215 - loss: 1.5921 - val_accuracy: 0.2031 - val_loss: 1.6107\n",
      "Epoch 72/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.2393 - loss: 1.5846 - val_accuracy: 0.1831 - val_loss: 1.6108\n",
      "Epoch 73/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.2141 - loss: 1.5973 - val_accuracy: 0.2089 - val_loss: 1.6130\n",
      "Epoch 74/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 639ms/step - accuracy: 0.2565 - loss: 1.5173 - val_accuracy: 0.1803 - val_loss: 1.6127\n",
      "Epoch 75/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.4280 - loss: 1.2183 - val_accuracy: 0.2089 - val_loss: 1.6155\n",
      "Epoch 76/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.2113 - loss: 1.5905 - val_accuracy: 0.1831 - val_loss: 1.6139\n",
      "Epoch 77/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.2181 - loss: 1.5688 - val_accuracy: 0.2089 - val_loss: 1.6110\n",
      "Epoch 78/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.7483 - loss: 0.6015 - val_accuracy: 0.1803 - val_loss: 1.6118\n",
      "Epoch 79/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.2483 - loss: 1.5723 - val_accuracy: 0.1831 - val_loss: 1.6132\n",
      "Epoch 80/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.2951 - loss: 1.5073 - val_accuracy: 0.2089 - val_loss: 1.6118\n",
      "Epoch 81/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.5843 - loss: 0.9235 - val_accuracy: 0.1831 - val_loss: 1.6137\n",
      "Epoch 82/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.1774 - loss: 1.6083 - val_accuracy: 0.1831 - val_loss: 1.6126\n",
      "Epoch 83/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.2113 - loss: 1.5895 - val_accuracy: 0.1831 - val_loss: 1.6104\n",
      "Epoch 84/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.2366 - loss: 1.5782 - val_accuracy: 0.1831 - val_loss: 1.6131\n",
      "Epoch 85/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.2715 - loss: 1.5462 - val_accuracy: 0.2031 - val_loss: 1.6097\n",
      "Epoch 86/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.2610 - loss: 1.5247 - val_accuracy: 0.1831 - val_loss: 1.6112\n",
      "Epoch 87/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 638ms/step - accuracy: 0.2426 - loss: 1.5608 - val_accuracy: 0.1831 - val_loss: 1.6115\n",
      "Epoch 88/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 639ms/step - accuracy: 0.2126 - loss: 1.5822 - val_accuracy: 0.1803 - val_loss: 1.6155\n",
      "Epoch 89/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.2321 - loss: 1.5985 - val_accuracy: 0.1831 - val_loss: 1.6096\n",
      "Epoch 90/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 639ms/step - accuracy: 0.2033 - loss: 1.5955 - val_accuracy: 0.1831 - val_loss: 1.6131\n",
      "Epoch 91/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 640ms/step - accuracy: 0.2231 - loss: 1.5918 - val_accuracy: 0.2031 - val_loss: 1.6098\n",
      "Epoch 92/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 639ms/step - accuracy: 0.2309 - loss: 1.5988 - val_accuracy: 0.1831 - val_loss: 1.6105\n",
      "Epoch 93/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 635ms/step - accuracy: 0.2526 - loss: 1.5591 - val_accuracy: 0.2031 - val_loss: 1.6134\n",
      "Epoch 94/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 633ms/step - accuracy: 0.2219 - loss: 1.5821 - val_accuracy: 0.1803 - val_loss: 1.6132\n",
      "Epoch 95/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.2097 - loss: 1.5947 - val_accuracy: 0.2089 - val_loss: 1.6136\n",
      "Epoch 96/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.2561 - loss: 1.5321 - val_accuracy: 0.2089 - val_loss: 1.6124\n",
      "Epoch 97/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 636ms/step - accuracy: 0.2844 - loss: 1.4871 - val_accuracy: 0.1803 - val_loss: 1.6120\n",
      "Epoch 98/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 637ms/step - accuracy: 0.2010 - loss: 1.6097 - val_accuracy: 0.1831 - val_loss: 1.6115\n",
      "Epoch 99/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.2507 - loss: 1.5244 - val_accuracy: 0.1831 - val_loss: 1.6113\n",
      "Epoch 100/100\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 642ms/step - accuracy: 0.2084 - loss: 1.5988 - val_accuracy: 0.1803 - val_loss: 1.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Train Accuracy: 0.2095101922750473, Validation Accuracy: 0.18025751411914825\n",
      "Fold 5 모델 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_models\\fold_5_model.h5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 338ms/step\n",
      "Fold 5 예측 결과 저장됨: C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_predictions\\fold_5_predictions.csv\n",
      "Average Train Accuracy: 0.20208776891231536\n",
      "Average Validation Accuracy: 0.18249867260456085\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from keras import layers, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def mish(inputs):\n",
    "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
    "\n",
    "# 데이터 로드 경로\n",
    "folder_path = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\Pupil\\crop_img\"\n",
    "results = pd.read_excel(\"results.xlsx\", header=None)\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, '*.jpg'))\n",
    "\n",
    "right_images = [file for file in files if 'right' in os.path.basename(file).lower()]\n",
    "left_images = [file for file in files if 'left' in os.path.basename(file).lower()]\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def load_and_preprocess_image(image_path, target_size=(64, 64)):\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "# 이미지 배열로 변환\n",
    "right_images = np.array([load_and_preprocess_image(img_path) for img_path in right_images])\n",
    "left_images = np.array([load_and_preprocess_image(img_path) for img_path in left_images])\n",
    "\n",
    "# 레이블 처리\n",
    "labels = results[0].values\n",
    "num_classes = len(np.unique(labels))\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# 커스텀 VGG19 모델 생성\n",
    "def create_custom_vgg_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional Block 1\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation=mish)(inputs)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 4\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 5\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation=mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_train_accuracies = []\n",
    "fold_val_accuracies = []\n",
    "\n",
    "# 모델 저장 경로\n",
    "model_save_folder = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_models\"\n",
    "if not os.path.exists(model_save_folder):\n",
    "    os.makedirs(model_save_folder)\n",
    "\n",
    "# CSV 파일 저장 경로\n",
    "csv_save_folder = r\"C:\\Users\\IMS\\Desktop\\Hwangsihoon\\WebCam\\vgg_predictions\"\n",
    "if not os.path.exists(csv_save_folder):\n",
    "    os.makedirs(csv_save_folder)\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(right_images)):\n",
    "    right_images_train, right_images_val = right_images[train_index], right_images[val_index]\n",
    "    left_images_train, left_images_val = left_images[train_index], left_images[val_index]\n",
    "    labels_train, labels_val = labels[train_index], labels[val_index]\n",
    "\n",
    "    cnn_right = create_custom_vgg_model((64, 64, 3))\n",
    "    cnn_left = create_custom_vgg_model((64, 64, 3))\n",
    "\n",
    "    # Flatten layers\n",
    "    right_flatten = layers.Flatten()(cnn_right.output)\n",
    "    left_flatten = layers.Flatten()(cnn_left.output)\n",
    "\n",
    "    # Concatenate\n",
    "    combined = layers.Concatenate()([right_flatten, left_flatten])\n",
    "\n",
    "    fc_output = layers.Dense(1024, activation=mish)(combined)\n",
    "    fc_output = layers.Dense(512, activation=mish)(fc_output)\n",
    "    fc_output = layers.Dense(256, activation=mish)(fc_output)\n",
    "    fc_output = layers.Dense(128, activation=mish)(fc_output)\n",
    "    fc_output = layers.BatchNormalization()(fc_output)\n",
    "    fc_output = layers.Dropout(0.5)(fc_output)\n",
    "    \n",
    "    final_output = layers.Dense(num_classes, activation='softmax')(fc_output)\n",
    "\n",
    "    model = Model(inputs=[cnn_right.input, cnn_left.input], outputs=final_output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit([right_images_train, left_images_train], labels_train,\n",
    "                        epochs=100,\n",
    "                        batch_size=8, \n",
    "                        validation_data=([right_images_val, left_images_val], labels_val))\n",
    "\n",
    "    fold_train_accuracies.append(history.history['accuracy'][-1])\n",
    "    fold_val_accuracies.append(history.history['val_accuracy'][-1])\n",
    "\n",
    "    print(f\"Fold {fold_idx+1} - Train Accuracy: {fold_train_accuracies[-1]}, Validation Accuracy: {fold_val_accuracies[-1]}\")\n",
    "\n",
    "    model_save_path = os.path.join(model_save_folder, f\"fold_{fold_idx+1}_model.h5\")\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Fold {fold_idx+1} 모델 저장됨: {model_save_path}\")\n",
    "\n",
    "    predictions = model.predict([right_images_val, left_images_val])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    actual_classes = np.argmax(labels_val, axis=1)\n",
    "\n",
    "    right_image_files_val = [os.path.basename(files[idx]) for idx in val_index]\n",
    "    left_image_files_val = [os.path.basename(files[idx]) for idx in val_index]\n",
    "\n",
    "    # CSV에 저장할 데이터\n",
    "    data = {\n",
    "        'Right Image': right_image_files_val,\n",
    "        'Left Image': left_image_files_val,\n",
    "        'Actual Class': actual_classes,\n",
    "        'Predicted Class': predicted_classes\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # CSV 파일 저장\n",
    "    csv_save_path = os.path.join(csv_save_folder, f\"fold_{fold_idx+1}_predictions.csv\")\n",
    "    df.to_csv(csv_save_path, index=False)\n",
    "    print(f\"Fold {fold_idx+1} 예측 결과 저장됨: {csv_save_path}\")\n",
    "\n",
    "avg_train_accuracy = np.mean(fold_train_accuracies)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "\n",
    "print(f'Average Train Accuracy: {avg_train_accuracy}')\n",
    "print(f'Average Validation Accuracy: {avg_val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc79ce50-b806-4341-911c-6653796ef113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_74\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_74\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_492 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_505 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_493 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_492[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_506 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_505[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_204             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_493[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_209             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_506[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_494 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_204[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_507 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_209[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_495 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_494[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_508 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_507[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_205             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_495[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_210             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_508[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_496 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_205[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_509 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_210[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_497 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_496[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_510 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_509[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_498 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_497[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_511 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_510[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_206             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_498[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_211             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_511[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_499 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_206[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_512 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_211[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_500 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_499[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_513 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_512[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_501 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_500[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_514 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_513[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_207             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_501[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_212             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_514[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ max_pooling2d_207[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_515 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ max_pooling2d_212[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_503 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_502[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_516 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_515[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_504 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_503[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_517 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_516[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_208             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_504[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_213             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_517[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_208[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_213[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ flatten_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,195,328</span> │ concatenate_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dense_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_52        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_59 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_60 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_492 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │ input_layer_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_505 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │ input_layer_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_493 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │ conv2d_492[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_506 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │ conv2d_505[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_204             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ conv2d_493[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_209             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ conv2d_506[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_494 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_204[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_507 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_209[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_495 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │ conv2d_494[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_508 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │ conv2d_507[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_205             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv2d_495[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_210             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ conv2d_508[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_496 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_205[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_509 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_210[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_497 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m590,080\u001b[0m │ conv2d_496[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_510 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m590,080\u001b[0m │ conv2d_509[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_498 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m590,080\u001b[0m │ conv2d_497[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_511 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m590,080\u001b[0m │ conv2d_510[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_206             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_498[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_211             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_511[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_499 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_206[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_512 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_211[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_500 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_499[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_513 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_512[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_501 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_500[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_514 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_513[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_207             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_501[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_212             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_514[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_502 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ max_pooling2d_207[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_515 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ max_pooling2d_212[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_503 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_502[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_516 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_515[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_504 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_503[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_517 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_516[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_208             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_504[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_213             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv2d_517[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_97 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ max_pooling2d_208[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_98 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ max_pooling2d_213[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_99 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_100 (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_28 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ flatten_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_80 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │       \u001b[38;5;34m4,195,328\u001b[0m │ concatenate_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_81 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │         \u001b[38;5;34m524,800\u001b[0m │ dense_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m131,328\u001b[0m │ dense_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ dense_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_52        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_52[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m645\u001b[0m │ dropout_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,944,145</span> (392.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,944,145\u001b[0m (392.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,314,629</span> (130.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,314,629\u001b[0m (130.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,629,260</span> (261.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m68,629,260\u001b[0m (261.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd52d5-c419-4ea0-9a9d-d191ee2afb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
