{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45e38b1-dc09-482a-adec-50faa104b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on subject: lgj\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_65', 'keras_tensor_130']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 210ms/step - accuracy: 0.1523 - loss: 2.8232 - val_accuracy: 0.1892 - val_loss: 3.4171\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 209ms/step - accuracy: 0.6097 - loss: 1.0176 - val_accuracy: 0.1569 - val_loss: 7.9537\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 209ms/step - accuracy: 0.8322 - loss: 0.4838 - val_accuracy: 0.1554 - val_loss: 7.1057\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 209ms/step - accuracy: 0.8842 - loss: 0.3755 - val_accuracy: 0.0954 - val_loss: 22.7871\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 209ms/step - accuracy: 0.9146 - loss: 0.2605 - val_accuracy: 0.1723 - val_loss: 11.4029\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 210ms/step - accuracy: 0.9461 - loss: 0.1759 - val_accuracy: 0.1569 - val_loss: 14.5608\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 210ms/step - accuracy: 0.9378 - loss: 0.2115 - val_accuracy: 0.1785 - val_loss: 19.4799\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 210ms/step - accuracy: 0.9616 - loss: 0.1493 - val_accuracy: 0.1323 - val_loss: 23.5767\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 210ms/step - accuracy: 0.9435 - loss: 0.2283 - val_accuracy: 0.1462 - val_loss: 26.0178\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 210ms/step - accuracy: 0.9771 - loss: 0.0924 - val_accuracy: 0.1262 - val_loss: 19.9419\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 211ms/step - accuracy: 0.9791 - loss: 0.0816 - val_accuracy: 0.1477 - val_loss: 24.5489\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 212ms/step - accuracy: 0.9670 - loss: 0.1131 - val_accuracy: 0.0862 - val_loss: 35.2431\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 213ms/step - accuracy: 0.9542 - loss: 0.1665 - val_accuracy: 0.1400 - val_loss: 40.1283\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 213ms/step - accuracy: 0.9600 - loss: 0.1192 - val_accuracy: 0.1000 - val_loss: 33.0685\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 213ms/step - accuracy: 0.9726 - loss: 0.1156 - val_accuracy: 0.1446 - val_loss: 42.0022\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 214ms/step - accuracy: 0.9851 - loss: 0.0645 - val_accuracy: 0.1492 - val_loss: 28.1693\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 215ms/step - accuracy: 0.9648 - loss: 0.1589 - val_accuracy: 0.1108 - val_loss: 44.5901\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 215ms/step - accuracy: 0.9740 - loss: 0.1050 - val_accuracy: 0.1200 - val_loss: 38.4803\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 216ms/step - accuracy: 0.9845 - loss: 0.0776 - val_accuracy: 0.1215 - val_loss: 47.5945\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 216ms/step - accuracy: 0.9839 - loss: 0.0650 - val_accuracy: 0.1046 - val_loss: 69.3498\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 217ms/step - accuracy: 0.9803 - loss: 0.0888 - val_accuracy: 0.0985 - val_loss: 71.7144\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 219ms/step - accuracy: 0.9801 - loss: 0.1081 - val_accuracy: 0.0815 - val_loss: 50.8828\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 217ms/step - accuracy: 0.9876 - loss: 0.0475 - val_accuracy: 0.1031 - val_loss: 70.3692\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 218ms/step - accuracy: 0.9794 - loss: 0.1099 - val_accuracy: 0.1077 - val_loss: 75.4137\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 218ms/step - accuracy: 0.9928 - loss: 0.0358 - val_accuracy: 0.1554 - val_loss: 23.6151\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 218ms/step - accuracy: 0.9518 - loss: 0.1879 - val_accuracy: 0.1154 - val_loss: 66.7736\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 218ms/step - accuracy: 0.9900 - loss: 0.0415 - val_accuracy: 0.1169 - val_loss: 118.0542\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 220ms/step - accuracy: 0.9701 - loss: 0.1239 - val_accuracy: 0.1262 - val_loss: 90.5519\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m574s\u001b[0m 221ms/step - accuracy: 0.9821 - loss: 0.0687 - val_accuracy: 0.1462 - val_loss: 69.2509\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 221ms/step - accuracy: 0.9904 - loss: 0.0310 - val_accuracy: 0.1431 - val_loss: 90.0024\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 222ms/step - accuracy: 0.9890 - loss: 0.0593 - val_accuracy: 0.1523 - val_loss: 75.8485\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 222ms/step - accuracy: 0.9878 - loss: 0.0756 - val_accuracy: 0.1523 - val_loss: 111.0227\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m579s\u001b[0m 223ms/step - accuracy: 0.9860 - loss: 0.0578 - val_accuracy: 0.1754 - val_loss: 61.1667\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 223ms/step - accuracy: 0.9886 - loss: 0.0583 - val_accuracy: 0.1492 - val_loss: 79.2923\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 224ms/step - accuracy: 0.9814 - loss: 0.1324 - val_accuracy: 0.1508 - val_loss: 70.7136\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m584s\u001b[0m 225ms/step - accuracy: 0.9788 - loss: 0.1264 - val_accuracy: 0.1338 - val_loss: 57.6346\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 225ms/step - accuracy: 0.9883 - loss: 0.0699 - val_accuracy: 0.1492 - val_loss: 97.4859\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 226ms/step - accuracy: 0.9812 - loss: 0.1097 - val_accuracy: 0.1138 - val_loss: 117.9744\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 229ms/step - accuracy: 0.9869 - loss: 0.0761 - val_accuracy: 0.1200 - val_loss: 76.0270\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 225ms/step - accuracy: 0.9863 - loss: 0.0611 - val_accuracy: 0.0954 - val_loss: 106.9529\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 226ms/step - accuracy: 0.9908 - loss: 0.0546 - val_accuracy: 0.1185 - val_loss: 74.7027\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 227ms/step - accuracy: 0.9781 - loss: 0.2138 - val_accuracy: 0.0985 - val_loss: 106.9629\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 229ms/step - accuracy: 0.9753 - loss: 0.1489 - val_accuracy: 0.0692 - val_loss: 113.7235\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 230ms/step - accuracy: 0.9903 - loss: 0.0651 - val_accuracy: 0.1031 - val_loss: 94.2704\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 231ms/step - accuracy: 0.9967 - loss: 0.0220 - val_accuracy: 0.1277 - val_loss: 142.2457\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 232ms/step - accuracy: 0.9981 - loss: 0.0027 - val_accuracy: 0.1400 - val_loss: 143.7267\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 233ms/step - accuracy: 0.9799 - loss: 0.1592 - val_accuracy: 0.0938 - val_loss: 171.1752\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 234ms/step - accuracy: 0.9763 - loss: 0.1873 - val_accuracy: 0.1031 - val_loss: 163.6499\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 235ms/step - accuracy: 0.9821 - loss: 0.1091 - val_accuracy: 0.1308 - val_loss: 206.9963\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 236ms/step - accuracy: 0.9858 - loss: 0.0928 - val_accuracy: 0.1215 - val_loss: 264.1033\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 549ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 510ms/step - accuracy: 0.1043 - loss: 150.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject lgj: 0.1215\n",
      "Results for subject lgj saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\1230_model_lgj.h5\n",
      "Testing on subject: hsb\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_139', 'keras_tensor_204', 'keras_tensor_269']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 229ms/step - accuracy: 0.1597 - loss: 2.7416 - val_accuracy: 0.2215 - val_loss: 2.8830\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 229ms/step - accuracy: 0.6582 - loss: 0.8933 - val_accuracy: 0.1185 - val_loss: 20.2611\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 229ms/step - accuracy: 0.8491 - loss: 0.4190 - val_accuracy: 0.2431 - val_loss: 3.7255\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 229ms/step - accuracy: 0.9085 - loss: 0.2999 - val_accuracy: 0.1385 - val_loss: 6.8726\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 229ms/step - accuracy: 0.9351 - loss: 0.1889 - val_accuracy: 0.2338 - val_loss: 6.3821\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 229ms/step - accuracy: 0.9338 - loss: 0.2108 - val_accuracy: 0.1708 - val_loss: 8.1696\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 229ms/step - accuracy: 0.9576 - loss: 0.1430 - val_accuracy: 0.2508 - val_loss: 7.9072\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 230ms/step - accuracy: 0.9634 - loss: 0.1365 - val_accuracy: 0.1877 - val_loss: 12.2873\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 230ms/step - accuracy: 0.9686 - loss: 0.1053 - val_accuracy: 0.1815 - val_loss: 15.5933\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 230ms/step - accuracy: 0.9582 - loss: 0.1506 - val_accuracy: 0.1646 - val_loss: 16.4882\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 231ms/step - accuracy: 0.9721 - loss: 0.1028 - val_accuracy: 0.1385 - val_loss: 16.1228\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 231ms/step - accuracy: 0.9633 - loss: 0.1289 - val_accuracy: 0.1262 - val_loss: 16.1722\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 231ms/step - accuracy: 0.9644 - loss: 0.1484 - val_accuracy: 0.1446 - val_loss: 16.6599\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 231ms/step - accuracy: 0.9719 - loss: 0.1073 - val_accuracy: 0.1738 - val_loss: 13.8839\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 231ms/step - accuracy: 0.9706 - loss: 0.1087 - val_accuracy: 0.1415 - val_loss: 18.7662\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 232ms/step - accuracy: 0.9861 - loss: 0.0551 - val_accuracy: 0.1338 - val_loss: 23.7512\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 232ms/step - accuracy: 0.9775 - loss: 0.0942 - val_accuracy: 0.1292 - val_loss: 26.3393\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 232ms/step - accuracy: 0.9831 - loss: 0.0602 - val_accuracy: 0.1354 - val_loss: 27.3677\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 232ms/step - accuracy: 0.9713 - loss: 0.1232 - val_accuracy: 0.0923 - val_loss: 30.2717\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 232ms/step - accuracy: 0.9853 - loss: 0.0672 - val_accuracy: 0.1000 - val_loss: 32.9822\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 232ms/step - accuracy: 0.9872 - loss: 0.0418 - val_accuracy: 0.0908 - val_loss: 55.4255\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 233ms/step - accuracy: 0.9819 - loss: 0.0826 - val_accuracy: 0.1046 - val_loss: 35.1725\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 232ms/step - accuracy: 0.9877 - loss: 0.0576 - val_accuracy: 0.1138 - val_loss: 44.4851\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 233ms/step - accuracy: 0.9915 - loss: 0.0397 - val_accuracy: 0.1015 - val_loss: 33.8173\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 233ms/step - accuracy: 0.9746 - loss: 0.1266 - val_accuracy: 0.1185 - val_loss: 49.4092\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 233ms/step - accuracy: 0.9857 - loss: 0.0530 - val_accuracy: 0.1138 - val_loss: 26.7937\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 234ms/step - accuracy: 0.9842 - loss: 0.0764 - val_accuracy: 0.1292 - val_loss: 32.5297\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 232ms/step - accuracy: 0.9876 - loss: 0.0576 - val_accuracy: 0.1062 - val_loss: 41.0046\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 233ms/step - accuracy: 0.9821 - loss: 0.0714 - val_accuracy: 0.1385 - val_loss: 51.3305\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 233ms/step - accuracy: 0.9801 - loss: 0.1157 - val_accuracy: 0.1108 - val_loss: 39.2713\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 233ms/step - accuracy: 0.9815 - loss: 0.1335 - val_accuracy: 0.1462 - val_loss: 30.0967\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 234ms/step - accuracy: 0.9856 - loss: 0.0725 - val_accuracy: 0.1292 - val_loss: 42.7111\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 234ms/step - accuracy: 0.9848 - loss: 0.0736 - val_accuracy: 0.0954 - val_loss: 52.8133\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 234ms/step - accuracy: 0.9857 - loss: 0.0793 - val_accuracy: 0.1000 - val_loss: 38.0949\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 234ms/step - accuracy: 0.9843 - loss: 0.0812 - val_accuracy: 0.0954 - val_loss: 54.5459\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 235ms/step - accuracy: 0.9849 - loss: 0.0823 - val_accuracy: 0.1062 - val_loss: 56.6303\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 235ms/step - accuracy: 0.9881 - loss: 0.0625 - val_accuracy: 0.0908 - val_loss: 39.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 235ms/step - accuracy: 0.9949 - loss: 0.0288 - val_accuracy: 0.0923 - val_loss: 51.1573\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 235ms/step - accuracy: 0.9868 - loss: 0.0729 - val_accuracy: 0.0954 - val_loss: 78.2890\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 235ms/step - accuracy: 0.9855 - loss: 0.1227 - val_accuracy: 0.1169 - val_loss: 189.9821\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 238ms/step - accuracy: 0.9809 - loss: 0.0931 - val_accuracy: 0.1046 - val_loss: 156.7542\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 246ms/step - accuracy: 0.9930 - loss: 0.0463 - val_accuracy: 0.1554 - val_loss: 50.6371\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 243ms/step - accuracy: 0.9755 - loss: 0.0824 - val_accuracy: 0.1077 - val_loss: 54.5041\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 236ms/step - accuracy: 0.9917 - loss: 0.0562 - val_accuracy: 0.1123 - val_loss: 48.3064\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 236ms/step - accuracy: 0.9957 - loss: 0.0359 - val_accuracy: 0.0938 - val_loss: 72.0891\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 236ms/step - accuracy: 0.9868 - loss: 0.0633 - val_accuracy: 0.1031 - val_loss: 37.0164\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 236ms/step - accuracy: 0.9872 - loss: 0.1203 - val_accuracy: 0.0985 - val_loss: 84.1255\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 237ms/step - accuracy: 0.9829 - loss: 0.0856 - val_accuracy: 0.1062 - val_loss: 72.8256\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 236ms/step - accuracy: 0.9964 - loss: 0.0138 - val_accuracy: 0.1154 - val_loss: 134.7883\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 237ms/step - accuracy: 0.9859 - loss: 0.1049 - val_accuracy: 0.1323 - val_loss: 75.5546\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 545ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 520ms/step - accuracy: 0.1339 - loss: 85.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject hsb: 0.1323\n",
      "Results for subject hsb saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\1230_model_hsb.h5\n",
      "Testing on subject: scy\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_278', 'keras_tensor_343', 'keras_tensor_408']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 255ms/step - accuracy: 0.1389 - loss: 2.6530 - val_accuracy: 0.2708 - val_loss: 2.8317\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 255ms/step - accuracy: 0.6147 - loss: 0.9807 - val_accuracy: 0.3338 - val_loss: 3.2534\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 255ms/step - accuracy: 0.8128 - loss: 0.5304 - val_accuracy: 0.2892 - val_loss: 6.6557\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 255ms/step - accuracy: 0.8882 - loss: 0.3299 - val_accuracy: 0.2169 - val_loss: 11.6175\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 255ms/step - accuracy: 0.9129 - loss: 0.2513 - val_accuracy: 0.1523 - val_loss: 85.2572\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 254ms/step - accuracy: 0.9312 - loss: 0.1924 - val_accuracy: 0.1615 - val_loss: 27.9909\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 254ms/step - accuracy: 0.9326 - loss: 0.1921 - val_accuracy: 0.2508 - val_loss: 55.0597\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 254ms/step - accuracy: 0.9483 - loss: 0.1656 - val_accuracy: 0.4185 - val_loss: 3.7941\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 254ms/step - accuracy: 0.9441 - loss: 0.1909 - val_accuracy: 0.3062 - val_loss: 5.1940\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 255ms/step - accuracy: 0.9546 - loss: 0.1711 - val_accuracy: 0.4969 - val_loss: 2.8898\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 256ms/step - accuracy: 0.9519 - loss: 0.1656 - val_accuracy: 0.3662 - val_loss: 5.1240\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 254ms/step - accuracy: 0.9638 - loss: 0.1141 - val_accuracy: 0.1662 - val_loss: 14.4364\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 255ms/step - accuracy: 0.9578 - loss: 0.1303 - val_accuracy: 0.3354 - val_loss: 6.6342\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 255ms/step - accuracy: 0.9645 - loss: 0.1071 - val_accuracy: 0.4231 - val_loss: 5.3470\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 255ms/step - accuracy: 0.9663 - loss: 0.1231 - val_accuracy: 0.4831 - val_loss: 4.2474\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 255ms/step - accuracy: 0.9692 - loss: 0.1279 - val_accuracy: 0.4877 - val_loss: 3.4477\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9707 - loss: 0.1193 - val_accuracy: 0.4446 - val_loss: 4.1531\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9808 - loss: 0.0622 - val_accuracy: 0.4508 - val_loss: 5.1408\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 255ms/step - accuracy: 0.9743 - loss: 0.1152 - val_accuracy: 0.1938 - val_loss: 13.5815\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9568 - loss: 0.1514 - val_accuracy: 0.1323 - val_loss: 30.1833\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9853 - loss: 0.0769 - val_accuracy: 0.3923 - val_loss: 7.2887\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9664 - loss: 0.1452 - val_accuracy: 0.4600 - val_loss: 7.1623\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9877 - loss: 0.0480 - val_accuracy: 0.1877 - val_loss: 8.5089\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 256ms/step - accuracy: 0.9697 - loss: 0.1154 - val_accuracy: 0.4631 - val_loss: 6.9319\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 256ms/step - accuracy: 0.9914 - loss: 0.0541 - val_accuracy: 0.3369 - val_loss: 8.6699\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 257ms/step - accuracy: 0.9850 - loss: 0.0573 - val_accuracy: 0.4400 - val_loss: 5.7018\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 257ms/step - accuracy: 0.9802 - loss: 0.0852 - val_accuracy: 0.5585 - val_loss: 3.6122\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9811 - loss: 0.0768 - val_accuracy: 0.2938 - val_loss: 10.2575\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 256ms/step - accuracy: 0.9742 - loss: 0.1627 - val_accuracy: 0.2246 - val_loss: 34.5565\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 256ms/step - accuracy: 0.9832 - loss: 0.0773 - val_accuracy: 0.2231 - val_loss: 85.9611\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 256ms/step - accuracy: 0.9779 - loss: 0.1723 - val_accuracy: 0.3523 - val_loss: 27.6039\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 256ms/step - accuracy: 0.9820 - loss: 0.0817 - val_accuracy: 0.4062 - val_loss: 25.0565\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 257ms/step - accuracy: 0.9808 - loss: 0.1205 - val_accuracy: 0.4615 - val_loss: 8.2582\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 257ms/step - accuracy: 0.9701 - loss: 0.1599 - val_accuracy: 0.4538 - val_loss: 6.8537\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 257ms/step - accuracy: 0.9916 - loss: 0.0385 - val_accuracy: 0.3631 - val_loss: 17.0575\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 257ms/step - accuracy: 0.9812 - loss: 0.0943 - val_accuracy: 0.2708 - val_loss: 10.6583\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 257ms/step - accuracy: 0.9884 - loss: 0.0617 - val_accuracy: 0.2677 - val_loss: 51.9014\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 257ms/step - accuracy: 0.9915 - loss: 0.0427 - val_accuracy: 0.2969 - val_loss: 10.7668\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 257ms/step - accuracy: 0.9886 - loss: 0.0571 - val_accuracy: 0.4769 - val_loss: 5.8192\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 257ms/step - accuracy: 0.9935 - loss: 0.0440 - val_accuracy: 0.2462 - val_loss: 29.1612\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 258ms/step - accuracy: 0.9799 - loss: 0.1198 - val_accuracy: 0.2738 - val_loss: 15.4791\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 258ms/step - accuracy: 0.9855 - loss: 0.0857 - val_accuracy: 0.5431 - val_loss: 5.5090\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 258ms/step - accuracy: 0.9836 - loss: 0.1025 - val_accuracy: 0.4738 - val_loss: 7.7697\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 258ms/step - accuracy: 0.9806 - loss: 0.0881 - val_accuracy: 0.2708 - val_loss: 10.0511\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 257ms/step - accuracy: 0.9892 - loss: 0.0420 - val_accuracy: 0.3523 - val_loss: 12.8539\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 258ms/step - accuracy: 0.9803 - loss: 0.1049 - val_accuracy: 0.4538 - val_loss: 8.4549\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 258ms/step - accuracy: 0.9851 - loss: 0.0831 - val_accuracy: 0.4523 - val_loss: 12.6747\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 258ms/step - accuracy: 0.9861 - loss: 0.1038 - val_accuracy: 0.6200 - val_loss: 4.2930\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 259ms/step - accuracy: 0.9949 - loss: 0.0712 - val_accuracy: 0.4785 - val_loss: 5.7932\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 259ms/step - accuracy: 0.9769 - loss: 0.1661 - val_accuracy: 0.4077 - val_loss: 12.5060\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 567ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 544ms/step - accuracy: 0.4396 - loss: 11.2421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject scy: 0.4077\n",
      "Results for subject scy saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\1230_model_scy.h5\n",
      "Average Accuracy: 0.2205\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "# Mish activation function\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    image = load_img(image_path, color_mode='rgb', target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "# 파일 이름에서 session과 point 추출\n",
    "def extract_session_and_point(filename):\n",
    "    session_match = re.search(r'img_(\\d+)', filename)\n",
    "    point_match = re.search(r'\\((\\d+)\\)', filename)\n",
    "    session = int(session_match.group(1)) if session_match else None\n",
    "    point = int(point_match.group(1)) if point_match else None\n",
    "    return session, point\n",
    "\n",
    "# ResNet18 모델 생성\n",
    "def create_resnet18_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, kernel_size=(5, 7), padding='same')(input_layer) # <- 기존 커널 7x7\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 3), padding='same')(x) # <- 기존 커널 3x3\n",
    "    filter_sizes = [64, 128, 256, 512]\n",
    "    num_blocks = [2, 2, 2, 2]\n",
    "    for filters, blocks in zip(filter_sizes, num_blocks):\n",
    "        for i in range(blocks):\n",
    "            x = resnet_block(x, filters, downsample=(i == 0 and filters != 64))\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# ResNet 블록 생성\n",
    "def resnet_block(x, filters, downsample=False):\n",
    "    shortcut = x\n",
    "    strides = (2, 2) if downsample else (1, 1)\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation(mish)(x)\n",
    "    return x\n",
    "\n",
    "# MLP 모델 생성\n",
    "def create_mlp_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation=mish)(input_layer)\n",
    "    x = layers.Dense(64, activation=mish)(x)\n",
    "    x = layers.Dense(3, activation=mish)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# 유효한 라벨 정의\n",
    "valid_labels = [1, 5, 9, 12, 16, 19, 23, 27, 30, 34, 37, 41, 45]\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "def prepare_data(folder_path, csv_path, test_subject, valid_labels):\n",
    "    subject_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "    train_subjects = [s for s in subject_folders if s != test_subject]\n",
    "    \n",
    "    # 학습 데이터 로드\n",
    "    train_images, train_csv_data = [], pd.DataFrame()\n",
    "    for train_subject in train_subjects:\n",
    "        train_folder = os.path.join(folder_path, train_subject)\n",
    "        train_csv = os.path.join(csv_path, f\"{train_subject}.csv\")\n",
    "        train_images.extend(glob.glob(os.path.join(train_folder, '*.jpg')))\n",
    "        if os.path.exists(train_csv):\n",
    "            train_csv_data = pd.concat([train_csv_data, pd.read_csv(train_csv)])\n",
    "    train_csv_data.rename(columns={'session': 'Session', 'point': 'Point'}, inplace=True)\n",
    "    \n",
    "    # 테스트 데이터 로드\n",
    "    test_folder = os.path.join(folder_path, test_subject)\n",
    "    test_csv = os.path.join(csv_path, f\"{test_subject}.csv\")\n",
    "    test_images = glob.glob(os.path.join(test_folder, '*.jpg'))\n",
    "    test_csv_data = pd.read_csv(test_csv) if os.path.exists(test_csv) else pd.DataFrame(columns=['Session', 'Point'])\n",
    "    test_csv_data.rename(columns={'session': 'Session', 'point': 'Point'}, inplace=True)\n",
    "    \n",
    "    # 데이터 처리 함수\n",
    "    def process_images(image_paths, csv_data, valid_labels):\n",
    "        image_data = []\n",
    "        for img in image_paths:\n",
    "            session, point = extract_session_and_point(os.path.basename(img))\n",
    "            if point in valid_labels:\n",
    "                subject_name = os.path.basename(os.path.dirname(img))\n",
    "                unique_filename = f\"{subject_name}_{os.path.basename(img)}\"\n",
    "                image_data.append({\n",
    "                    'Filename': os.path.abspath(img),\n",
    "                    'UniqueFilename': unique_filename,\n",
    "                    'Session': session,\n",
    "                    'Point': point\n",
    "                })\n",
    "        df = pd.DataFrame(image_data)\n",
    "        merged = pd.merge(df, csv_data, on=['Session', 'Point'], how='inner')\n",
    "        merged = merged.drop_duplicates(subset=['UniqueFilename', 'Session', 'Point'])\n",
    "        merged = merged[merged['Point'].isin(valid_labels)]\n",
    "        return merged\n",
    "    \n",
    "    train_df = process_images(train_images, train_csv_data, valid_labels)\n",
    "    test_df = process_images(test_images, test_csv_data, valid_labels)\n",
    "    return train_df, test_df\n",
    "\n",
    "# 모델 훈련 및 평가\n",
    "def train_and_evaluate(folder_path, csv_path, valid_labels, test_subjects):\n",
    "    accuracies = []\n",
    "    for test_subject in test_subjects:\n",
    "        print(f\"Testing on subject: {test_subject}\")\n",
    "        train_df, test_df = prepare_data(folder_path, csv_path, test_subject, valid_labels)\n",
    "        \n",
    "        train_images_array = np.array([load_and_preprocess_image(path) for path in train_df['Filename']])\n",
    "        train_features = train_df.drop(['Filename', 'UniqueFilename', 'Session', 'Point'], axis=1).values\n",
    "        train_labels = train_df['Point'].map({label: idx for idx, label in enumerate(valid_labels)}).values\n",
    "        train_labels = to_categorical(train_labels, num_classes=len(valid_labels))\n",
    "        \n",
    "        test_images_array = np.array([load_and_preprocess_image(path) for path in test_df['Filename']])\n",
    "        test_features = test_df.drop(['Filename', 'UniqueFilename', 'Session', 'Point'], axis=1).values\n",
    "        test_labels = test_df['Point'].map({label: idx for idx, label in enumerate(valid_labels)}).values\n",
    "        test_labels = to_categorical(test_labels, num_classes=len(valid_labels))\n",
    "        \n",
    "        right_eye_model = create_resnet18_model((128, 128, 3))\n",
    "        left_eye_model = create_resnet18_model((128, 128, 3))\n",
    "        mlp_model = create_mlp_model(train_features.shape[1:])\n",
    "        combined_input = layers.concatenate([right_eye_model.output, left_eye_model.output, mlp_model.output])\n",
    "        x = layers.Dense(256, activation=mish)(combined_input)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "        # x = layers.Dense(128, activation=mish)(x)  # 새로운 Dense 계층 추가\n",
    "        # x = layers.Dropout(0.4)(x)  # Dropout 추가\n",
    "        \n",
    "        # x = layers.Dense(64, activation=mish)(x)  # 또 다른 Dense 계층 추가\n",
    "        # x = layers.Dropout(0.3)(x)  # Dropout 추가\n",
    "\n",
    "        output_layer = layers.Dense(len(valid_labels), activation='softmax')(x)\n",
    "        combined_model = Model(inputs=[right_eye_model.input, left_eye_model.input, mlp_model.input], outputs=output_layer)\n",
    "\n",
    "        combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = combined_model.fit(\n",
    "            [train_images_array, train_images_array, train_features], train_labels,\n",
    "            validation_data=([test_images_array, test_images_array, test_features], test_labels),\n",
    "            epochs=50,\n",
    "            batch_size=1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        predictions = combined_model.predict([test_images_array, test_images_array, test_features])\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        actual_classes = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        loss, accuracy = combined_model.evaluate([test_images_array, test_images_array, test_features], test_labels)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Testing accuracy for subject {test_subject}: {accuracy:.4f}\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        results = []\n",
    "        for idx, (image_path, feature, pred_class, actual_class) in enumerate(zip(\n",
    "            test_df['Filename'], test_features, predicted_classes, actual_classes)):\n",
    "            results.append({\n",
    "                'Subject': test_subject,\n",
    "                'Test Accuracy': accuracy,\n",
    "                'Test Loss': loss,\n",
    "                'Image File': image_path,\n",
    "                'Feature': feature.tolist(),\n",
    "                'Predicted Class': pred_class,\n",
    "                'Actual Class': actual_class\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(csv_path, f\"1230_results_{test_subject}.csv\"), index=False, encoding='utf-8')\n",
    "        print(f\"Results for subject {test_subject} saved.\")\n",
    "        \n",
    "        # 모델 저장\n",
    "        model_save_path = os.path.join(csv_path, f\"1230_model_{test_subject}.h5\")\n",
    "        combined_model.save(model_save_path)\n",
    "        print(f\"Model saved at: {model_save_path}\")\n",
    "    \n",
    "    print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "# 데이터 경로\n",
    "folder_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\img\"\n",
    "csv_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\"\n",
    "test_subjects = ['lgj', 'hsb', 'scy']  # 테스트로 사용할 대상\n",
    "\n",
    "# LOSO 수행\n",
    "train_and_evaluate(folder_path, csv_path, valid_labels, test_subjects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
