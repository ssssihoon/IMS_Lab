{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b091fd8-7707-40c4-80aa-ede2b5af62f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on subject: lgj\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_143', 'keras_tensor_208', 'keras_tensor_273']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 156ms/step - accuracy: 0.1912 - loss: 2.6463 - val_accuracy: 0.3831 - val_loss: 1.6987\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 154ms/step - accuracy: 0.6080 - loss: 1.0894 - val_accuracy: 0.3708 - val_loss: 1.9354\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 155ms/step - accuracy: 0.8040 - loss: 0.5692 - val_accuracy: 0.3508 - val_loss: 3.5242\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 155ms/step - accuracy: 0.8619 - loss: 0.4085 - val_accuracy: 0.3046 - val_loss: 4.2515\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 155ms/step - accuracy: 0.9045 - loss: 0.3124 - val_accuracy: 0.3077 - val_loss: 8.0670\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 155ms/step - accuracy: 0.9079 - loss: 0.2686 - val_accuracy: 0.2000 - val_loss: 12.0939\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 155ms/step - accuracy: 0.9319 - loss: 0.2308 - val_accuracy: 0.2446 - val_loss: 16.5291\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 155ms/step - accuracy: 0.9346 - loss: 0.1996 - val_accuracy: 0.2200 - val_loss: 10.9680\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 155ms/step - accuracy: 0.9316 - loss: 0.1925 - val_accuracy: 0.2431 - val_loss: 16.1316\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 155ms/step - accuracy: 0.9516 - loss: 0.1606 - val_accuracy: 0.1923 - val_loss: 20.6393\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 155ms/step - accuracy: 0.9569 - loss: 0.1410 - val_accuracy: 0.3000 - val_loss: 5.5804\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 155ms/step - accuracy: 0.9539 - loss: 0.1494 - val_accuracy: 0.1123 - val_loss: 22.7205\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 155ms/step - accuracy: 0.9598 - loss: 0.1281 - val_accuracy: 0.1477 - val_loss: 25.0505\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 155ms/step - accuracy: 0.9711 - loss: 0.1094 - val_accuracy: 0.0815 - val_loss: 24.7507\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 155ms/step - accuracy: 0.9623 - loss: 0.1576 - val_accuracy: 0.2138 - val_loss: 24.6550\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9709 - loss: 0.0975 - val_accuracy: 0.1662 - val_loss: 18.2266\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9657 - loss: 0.1057 - val_accuracy: 0.1708 - val_loss: 24.0865\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9651 - loss: 0.1353 - val_accuracy: 0.1492 - val_loss: 27.3266\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9678 - loss: 0.1155 - val_accuracy: 0.1908 - val_loss: 24.1109\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9794 - loss: 0.0756 - val_accuracy: 0.1246 - val_loss: 41.1261\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9667 - loss: 0.1247 - val_accuracy: 0.1923 - val_loss: 23.3426\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9724 - loss: 0.1072 - val_accuracy: 0.2585 - val_loss: 10.5332\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9660 - loss: 0.1701 - val_accuracy: 0.0862 - val_loss: 38.0174\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9739 - loss: 0.0883 - val_accuracy: 0.3046 - val_loss: 11.9849\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9829 - loss: 0.0859 - val_accuracy: 0.0938 - val_loss: 28.4459\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9617 - loss: 0.1427 - val_accuracy: 0.1385 - val_loss: 29.0834\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9776 - loss: 0.1292 - val_accuracy: 0.1662 - val_loss: 26.2326\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9761 - loss: 0.0980 - val_accuracy: 0.1723 - val_loss: 34.5166\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9817 - loss: 0.0990 - val_accuracy: 0.1662 - val_loss: 32.2011\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 156ms/step - accuracy: 0.9847 - loss: 0.0721 - val_accuracy: 0.1800 - val_loss: 21.7362\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 156ms/step - accuracy: 0.9802 - loss: 0.0818 - val_accuracy: 0.1323 - val_loss: 26.3417\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9782 - loss: 0.0981 - val_accuracy: 0.1692 - val_loss: 16.3453\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9559 - loss: 0.2103 - val_accuracy: 0.2154 - val_loss: 16.3369\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9868 - loss: 0.0556 - val_accuracy: 0.0708 - val_loss: 42.1221\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9636 - loss: 0.1622 - val_accuracy: 0.1738 - val_loss: 24.7679\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9801 - loss: 0.1033 - val_accuracy: 0.1554 - val_loss: 25.7779\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9804 - loss: 0.1032 - val_accuracy: 0.0846 - val_loss: 41.8029\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9837 - loss: 0.0927 - val_accuracy: 0.1062 - val_loss: 36.5064\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9782 - loss: 0.1643 - val_accuracy: 0.1354 - val_loss: 24.8747\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 158ms/step - accuracy: 0.9906 - loss: 0.0406 - val_accuracy: 0.2092 - val_loss: 22.9807\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 158ms/step - accuracy: 0.9795 - loss: 0.1284 - val_accuracy: 0.1923 - val_loss: 14.4628\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 159ms/step - accuracy: 0.9964 - loss: 0.0237 - val_accuracy: 0.2031 - val_loss: 24.8266\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9695 - loss: 0.2328 - val_accuracy: 0.1231 - val_loss: 31.0846\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9878 - loss: 0.0412 - val_accuracy: 0.1985 - val_loss: 20.0917\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9827 - loss: 0.0918 - val_accuracy: 0.1523 - val_loss: 21.7805\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 159ms/step - accuracy: 0.9869 - loss: 0.0598 - val_accuracy: 0.2323 - val_loss: 23.2256\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9806 - loss: 0.1151 - val_accuracy: 0.2431 - val_loss: 14.0861\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9844 - loss: 0.0572 - val_accuracy: 0.1969 - val_loss: 34.3059\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9839 - loss: 0.0736 - val_accuracy: 0.1708 - val_loss: 27.4512\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9769 - loss: 0.1437 - val_accuracy: 0.1200 - val_loss: 31.2608\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.1002 - loss: 28.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject lgj: 0.1200\n",
      "Results for subject lgj saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\1127_model_lgj.h5\n",
      "Testing on subject: hsb\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_282', 'keras_tensor_347', 'keras_tensor_412']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 157ms/step - accuracy: 0.2530 - loss: 2.4173 - val_accuracy: 0.1154 - val_loss: 2.9013\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 158ms/step - accuracy: 0.6442 - loss: 0.9415 - val_accuracy: 0.1600 - val_loss: 4.3066\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.8337 - loss: 0.4518 - val_accuracy: 0.1292 - val_loss: 8.9293\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.8972 - loss: 0.3110 - val_accuracy: 0.0985 - val_loss: 16.1058\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9293 - loss: 0.2323 - val_accuracy: 0.0800 - val_loss: 17.9534\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9159 - loss: 0.2479 - val_accuracy: 0.1492 - val_loss: 12.2793\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9550 - loss: 0.1453 - val_accuracy: 0.1000 - val_loss: 18.8414\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 156ms/step - accuracy: 0.9502 - loss: 0.1572 - val_accuracy: 0.1615 - val_loss: 16.8480\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9564 - loss: 0.1532 - val_accuracy: 0.1200 - val_loss: 17.6617\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 156ms/step - accuracy: 0.9595 - loss: 0.1712 - val_accuracy: 0.1215 - val_loss: 18.5304\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 156ms/step - accuracy: 0.9491 - loss: 0.2115 - val_accuracy: 0.1246 - val_loss: 18.4595\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9730 - loss: 0.1042 - val_accuracy: 0.1354 - val_loss: 22.9968\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9671 - loss: 0.1217 - val_accuracy: 0.1554 - val_loss: 17.4174\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9807 - loss: 0.0693 - val_accuracy: 0.1462 - val_loss: 18.8867\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9761 - loss: 0.0886 - val_accuracy: 0.1354 - val_loss: 24.0607\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9677 - loss: 0.1321 - val_accuracy: 0.1246 - val_loss: 22.8154\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9670 - loss: 0.1235 - val_accuracy: 0.1723 - val_loss: 13.2493\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9786 - loss: 0.1016 - val_accuracy: 0.1400 - val_loss: 16.5454\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 158ms/step - accuracy: 0.9532 - loss: 0.1771 - val_accuracy: 0.1354 - val_loss: 11.4227\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 158ms/step - accuracy: 0.9650 - loss: 0.1742 - val_accuracy: 0.1446 - val_loss: 12.1250\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 158ms/step - accuracy: 0.9596 - loss: 0.1725 - val_accuracy: 0.1969 - val_loss: 8.4557\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 159ms/step - accuracy: 0.9764 - loss: 0.0771 - val_accuracy: 0.1462 - val_loss: 10.6691\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 159ms/step - accuracy: 0.9776 - loss: 0.0710 - val_accuracy: 0.1338 - val_loss: 11.4625\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 159ms/step - accuracy: 0.9740 - loss: 0.1148 - val_accuracy: 0.0908 - val_loss: 13.8367\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 159ms/step - accuracy: 0.9928 - loss: 0.0415 - val_accuracy: 0.1077 - val_loss: 14.2122\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 159ms/step - accuracy: 0.9741 - loss: 0.1162 - val_accuracy: 0.1308 - val_loss: 15.3281\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 159ms/step - accuracy: 0.9701 - loss: 0.1311 - val_accuracy: 0.1215 - val_loss: 12.6319\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 159ms/step - accuracy: 0.9678 - loss: 0.1229 - val_accuracy: 0.1646 - val_loss: 10.1224\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 159ms/step - accuracy: 0.9809 - loss: 0.1435 - val_accuracy: 0.1569 - val_loss: 10.9839\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9903 - loss: 0.0274 - val_accuracy: 0.0908 - val_loss: 19.8894\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9534 - loss: 0.1914 - val_accuracy: 0.2062 - val_loss: 9.6099\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9773 - loss: 0.1216 - val_accuracy: 0.1569 - val_loss: 9.9642\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 159ms/step - accuracy: 0.9849 - loss: 0.0722 - val_accuracy: 0.2031 - val_loss: 10.8951\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9818 - loss: 0.0820 - val_accuracy: 0.1508 - val_loss: 10.7494\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9851 - loss: 0.0605 - val_accuracy: 0.1646 - val_loss: 12.0460\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9934 - loss: 0.0287 - val_accuracy: 0.1631 - val_loss: 9.3412\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9709 - loss: 0.0944 - val_accuracy: 0.1708 - val_loss: 9.2100\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9845 - loss: 0.0755 - val_accuracy: 0.1523 - val_loss: 14.8150\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9796 - loss: 0.0960 - val_accuracy: 0.1554 - val_loss: 10.1298\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9782 - loss: 0.1080 - val_accuracy: 0.2015 - val_loss: 7.7796\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9886 - loss: 0.0568 - val_accuracy: 0.1646 - val_loss: 11.0300\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9901 - loss: 0.0428 - val_accuracy: 0.1400 - val_loss: 18.8448\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9855 - loss: 0.0543 - val_accuracy: 0.0954 - val_loss: 20.6841\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9775 - loss: 0.0971 - val_accuracy: 0.1338 - val_loss: 20.8795\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 161ms/step - accuracy: 0.9779 - loss: 0.0873 - val_accuracy: 0.1385 - val_loss: 12.5960\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 159ms/step - accuracy: 0.9907 - loss: 0.0477 - val_accuracy: 0.1508 - val_loss: 18.7863\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9850 - loss: 0.1127 - val_accuracy: 0.1246 - val_loss: 26.8658\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9878 - loss: 0.0753 - val_accuracy: 0.2154 - val_loss: 8.8272\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9855 - loss: 0.0756 - val_accuracy: 0.1938 - val_loss: 14.0613\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 161ms/step - accuracy: 0.9865 - loss: 0.0669 - val_accuracy: 0.1354 - val_loss: 16.5843\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.1196 - loss: 18.9019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject hsb: 0.1354\n",
      "Results for subject hsb saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\1127_model_hsb.h5\n",
      "Testing on subject: scy\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_421', 'keras_tensor_486', 'keras_tensor_551']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 164ms/step - accuracy: 0.2201 - loss: 2.5185 - val_accuracy: 0.1631 - val_loss: 3.7586\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 164ms/step - accuracy: 0.6133 - loss: 0.9596 - val_accuracy: 0.2723 - val_loss: 3.4516\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 165ms/step - accuracy: 0.7664 - loss: 0.6554 - val_accuracy: 0.3246 - val_loss: 3.3002\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 165ms/step - accuracy: 0.8581 - loss: 0.4075 - val_accuracy: 0.2108 - val_loss: 6.3167\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 164ms/step - accuracy: 0.8957 - loss: 0.3047 - val_accuracy: 0.2062 - val_loss: 6.1678\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 165ms/step - accuracy: 0.9012 - loss: 0.2642 - val_accuracy: 0.2877 - val_loss: 6.3461\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 164ms/step - accuracy: 0.9321 - loss: 0.2203 - val_accuracy: 0.2185 - val_loss: 10.5906\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 164ms/step - accuracy: 0.9499 - loss: 0.1738 - val_accuracy: 0.3215 - val_loss: 7.6104\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 165ms/step - accuracy: 0.9481 - loss: 0.1637 - val_accuracy: 0.2800 - val_loss: 8.4282\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 165ms/step - accuracy: 0.9432 - loss: 0.1800 - val_accuracy: 0.2200 - val_loss: 13.4466\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 165ms/step - accuracy: 0.9544 - loss: 0.1257 - val_accuracy: 0.2523 - val_loss: 13.3591\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 165ms/step - accuracy: 0.9448 - loss: 0.1911 - val_accuracy: 0.2031 - val_loss: 16.1240\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 170ms/step - accuracy: 0.9589 - loss: 0.1456 - val_accuracy: 0.2108 - val_loss: 14.7639\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 171ms/step - accuracy: 0.9575 - loss: 0.1731 - val_accuracy: 0.2662 - val_loss: 13.6928\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 170ms/step - accuracy: 0.9581 - loss: 0.1529 - val_accuracy: 0.2600 - val_loss: 15.9395\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 170ms/step - accuracy: 0.9723 - loss: 0.0907 - val_accuracy: 0.2692 - val_loss: 17.6236\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 169ms/step - accuracy: 0.9615 - loss: 0.1341 - val_accuracy: 0.3877 - val_loss: 6.2578\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 171ms/step - accuracy: 0.9804 - loss: 0.0845 - val_accuracy: 0.2862 - val_loss: 10.2124\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 168ms/step - accuracy: 0.9734 - loss: 0.1171 - val_accuracy: 0.2046 - val_loss: 21.2279\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 167ms/step - accuracy: 0.9830 - loss: 0.0844 - val_accuracy: 0.2631 - val_loss: 23.6856\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 164ms/step - accuracy: 0.9780 - loss: 0.0828 - val_accuracy: 0.2877 - val_loss: 25.3244\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 166ms/step - accuracy: 0.9651 - loss: 0.1318 - val_accuracy: 0.2677 - val_loss: 14.5938\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 166ms/step - accuracy: 0.9843 - loss: 0.0745 - val_accuracy: 0.3600 - val_loss: 10.6489\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 167ms/step - accuracy: 0.9837 - loss: 0.0437 - val_accuracy: 0.2492 - val_loss: 37.3493\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 167ms/step - accuracy: 0.9636 - loss: 0.1599 - val_accuracy: 0.3154 - val_loss: 20.3138\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 168ms/step - accuracy: 0.9865 - loss: 0.0621 - val_accuracy: 0.2154 - val_loss: 50.5350\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 172ms/step - accuracy: 0.9733 - loss: 0.0942 - val_accuracy: 0.2431 - val_loss: 25.8597\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 171ms/step - accuracy: 0.9710 - loss: 0.1234 - val_accuracy: 0.3677 - val_loss: 15.3147\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 166ms/step - accuracy: 0.9741 - loss: 0.0909 - val_accuracy: 0.2754 - val_loss: 30.0644\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 166ms/step - accuracy: 0.9858 - loss: 0.0633 - val_accuracy: 0.2138 - val_loss: 55.8274\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 167ms/step - accuracy: 0.9775 - loss: 0.1177 - val_accuracy: 0.2985 - val_loss: 28.0120\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 171ms/step - accuracy: 0.9853 - loss: 0.0626 - val_accuracy: 0.2262 - val_loss: 39.1490\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 171ms/step - accuracy: 0.9787 - loss: 0.0823 - val_accuracy: 0.1677 - val_loss: 96.4392\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 170ms/step - accuracy: 0.9630 - loss: 0.2094 - val_accuracy: 0.2308 - val_loss: 24.1209\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 168ms/step - accuracy: 0.9738 - loss: 0.1397 - val_accuracy: 0.2677 - val_loss: 46.2202\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 168ms/step - accuracy: 0.9663 - loss: 0.1501 - val_accuracy: 0.2046 - val_loss: 70.7523\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 168ms/step - accuracy: 0.9681 - loss: 0.1253 - val_accuracy: 0.1969 - val_loss: 126.6138\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 168ms/step - accuracy: 0.9870 - loss: 0.0648 - val_accuracy: 0.2308 - val_loss: 37.3497\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 168ms/step - accuracy: 0.9777 - loss: 0.1121 - val_accuracy: 0.2862 - val_loss: 23.3053\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 168ms/step - accuracy: 0.9766 - loss: 0.1480 - val_accuracy: 0.1785 - val_loss: 65.2156\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 168ms/step - accuracy: 0.9807 - loss: 0.1144 - val_accuracy: 0.2323 - val_loss: 51.5164\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 168ms/step - accuracy: 0.9888 - loss: 0.0654 - val_accuracy: 0.2738 - val_loss: 26.9144\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 168ms/step - accuracy: 0.9823 - loss: 0.0719 - val_accuracy: 0.2338 - val_loss: 39.7709\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 168ms/step - accuracy: 0.9916 - loss: 0.0438 - val_accuracy: 0.2338 - val_loss: 67.8685\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 169ms/step - accuracy: 0.9721 - loss: 0.1444 - val_accuracy: 0.2677 - val_loss: 25.8872\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 168ms/step - accuracy: 0.9887 - loss: 0.0617 - val_accuracy: 0.2277 - val_loss: 20.7873\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 168ms/step - accuracy: 0.9835 - loss: 0.1415 - val_accuracy: 0.1892 - val_loss: 69.3325\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 169ms/step - accuracy: 0.9801 - loss: 0.0892 - val_accuracy: 0.2892 - val_loss: 31.9190\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 169ms/step - accuracy: 0.9806 - loss: 0.0924 - val_accuracy: 0.2615 - val_loss: 31.8602\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 169ms/step - accuracy: 0.9668 - loss: 0.1721 - val_accuracy: 0.2862 - val_loss: 46.8732\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.3569 - loss: 26.4770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject scy: 0.2862\n",
      "Results for subject scy saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\1127_model_scy.h5\n",
      "Average Accuracy: 0.1805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "# Mish activation function\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    image = load_img(image_path, color_mode='rgb', target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "# 파일 이름에서 session과 point 추출\n",
    "def extract_session_and_point(filename):\n",
    "    session_match = re.search(r'img_(\\d+)', filename)\n",
    "    point_match = re.search(r'\\((\\d+)\\)', filename)\n",
    "    session = int(session_match.group(1)) if session_match else None\n",
    "    point = int(point_match.group(1)) if point_match else None\n",
    "    return session, point\n",
    "\n",
    "# ResNet18 모델 생성\n",
    "def create_resnet18_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    filter_sizes = [64, 128, 256, 512]\n",
    "    num_blocks = [2, 2, 2, 2]\n",
    "    for filters, blocks in zip(filter_sizes, num_blocks):\n",
    "        for i in range(blocks):\n",
    "            x = resnet_block(x, filters, downsample=(i == 0 and filters != 64))\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# ResNet 블록 생성\n",
    "def resnet_block(x, filters, downsample=False):\n",
    "    shortcut = x\n",
    "    strides = (2, 2) if downsample else (1, 1)\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation(mish)(x)\n",
    "    return x\n",
    "\n",
    "# MLP 모델 생성\n",
    "def create_mlp_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation=mish)(input_layer)\n",
    "    x = layers.Dense(64, activation=mish)(x)\n",
    "    x = layers.Dense(3, activation=mish)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# 유효한 라벨 정의\n",
    "valid_labels = [1, 5, 9, 12, 16, 19, 23, 27, 30, 34, 37, 41, 45]\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "def prepare_data(folder_path, csv_path, test_subject, valid_labels):\n",
    "    subject_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "    train_subjects = [s for s in subject_folders if s != test_subject]\n",
    "    \n",
    "    # 학습 데이터 로드\n",
    "    train_images, train_csv_data = [], pd.DataFrame()\n",
    "    for train_subject in train_subjects:\n",
    "        train_folder = os.path.join(folder_path, train_subject)\n",
    "        train_csv = os.path.join(csv_path, f\"{train_subject}.csv\")\n",
    "        train_images.extend(glob.glob(os.path.join(train_folder, '*.jpg')))\n",
    "        if os.path.exists(train_csv):\n",
    "            train_csv_data = pd.concat([train_csv_data, pd.read_csv(train_csv)])\n",
    "    train_csv_data.rename(columns={'session': 'Session', 'point': 'Point'}, inplace=True)\n",
    "    \n",
    "    # 테스트 데이터 로드\n",
    "    test_folder = os.path.join(folder_path, test_subject)\n",
    "    test_csv = os.path.join(csv_path, f\"{test_subject}.csv\")\n",
    "    test_images = glob.glob(os.path.join(test_folder, '*.jpg'))\n",
    "    test_csv_data = pd.read_csv(test_csv) if os.path.exists(test_csv) else pd.DataFrame(columns=['Session', 'Point'])\n",
    "    test_csv_data.rename(columns={'session': 'Session', 'point': 'Point'}, inplace=True)\n",
    "    \n",
    "    # 데이터 처리 함수\n",
    "    def process_images(image_paths, csv_data, valid_labels):\n",
    "        image_data = []\n",
    "        for img in image_paths:\n",
    "            session, point = extract_session_and_point(os.path.basename(img))\n",
    "            if point in valid_labels:\n",
    "                subject_name = os.path.basename(os.path.dirname(img))\n",
    "                unique_filename = f\"{subject_name}_{os.path.basename(img)}\"\n",
    "                image_data.append({\n",
    "                    'Filename': os.path.abspath(img),\n",
    "                    'UniqueFilename': unique_filename,\n",
    "                    'Session': session,\n",
    "                    'Point': point\n",
    "                })\n",
    "        df = pd.DataFrame(image_data)\n",
    "        merged = pd.merge(df, csv_data, on=['Session', 'Point'], how='inner')\n",
    "        merged = merged.drop_duplicates(subset=['UniqueFilename', 'Session', 'Point'])\n",
    "        merged = merged[merged['Point'].isin(valid_labels)]\n",
    "        return merged\n",
    "    \n",
    "    train_df = process_images(train_images, train_csv_data, valid_labels)\n",
    "    test_df = process_images(test_images, test_csv_data, valid_labels)\n",
    "    return train_df, test_df\n",
    "\n",
    "# 모델 훈련 및 평가\n",
    "def train_and_evaluate(folder_path, csv_path, valid_labels, test_subjects):\n",
    "    accuracies = []\n",
    "    for test_subject in test_subjects:\n",
    "        print(f\"Testing on subject: {test_subject}\")\n",
    "        train_df, test_df = prepare_data(folder_path, csv_path, test_subject, valid_labels)\n",
    "        \n",
    "        train_images_array = np.array([load_and_preprocess_image(path) for path in train_df['Filename']])\n",
    "        train_features = train_df.drop(['Filename', 'UniqueFilename', 'Session', 'Point'], axis=1).values\n",
    "        train_labels = train_df['Point'].map({label: idx for idx, label in enumerate(valid_labels)}).values\n",
    "        train_labels = to_categorical(train_labels, num_classes=len(valid_labels))\n",
    "        \n",
    "        test_images_array = np.array([load_and_preprocess_image(path) for path in test_df['Filename']])\n",
    "        test_features = test_df.drop(['Filename', 'UniqueFilename', 'Session', 'Point'], axis=1).values\n",
    "        test_labels = test_df['Point'].map({label: idx for idx, label in enumerate(valid_labels)}).values\n",
    "        test_labels = to_categorical(test_labels, num_classes=len(valid_labels))\n",
    "        \n",
    "        right_eye_model = create_resnet18_model((128, 128, 3))\n",
    "        left_eye_model = create_resnet18_model((128, 128, 3))\n",
    "        mlp_model = create_mlp_model(train_features.shape[1:])\n",
    "        combined_input = layers.concatenate([right_eye_model.output, left_eye_model.output, mlp_model.output])\n",
    "        x = layers.Dense(256, activation=mish)(combined_input)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "        # x = layers.Dense(128, activation=mish)(x)  # 새로운 Dense 계층 추가\n",
    "        # x = layers.Dropout(0.4)(x)  # Dropout 추가\n",
    "        \n",
    "        # x = layers.Dense(64, activation=mish)(x)  # 또 다른 Dense 계층 추가\n",
    "        # x = layers.Dropout(0.3)(x)  # Dropout 추가\n",
    "\n",
    "        output_layer = layers.Dense(len(valid_labels), activation='softmax')(x)\n",
    "        combined_model = Model(inputs=[right_eye_model.input, left_eye_model.input, mlp_model.input], outputs=output_layer)\n",
    "\n",
    "        combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = combined_model.fit(\n",
    "            [train_images_array, train_images_array, train_features], train_labels,\n",
    "            validation_data=([test_images_array, test_images_array, test_features], test_labels),\n",
    "            epochs=50,\n",
    "            batch_size=1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        predictions = combined_model.predict([test_images_array, test_images_array, test_features])\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        actual_classes = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        loss, accuracy = combined_model.evaluate([test_images_array, test_images_array, test_features], test_labels)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Testing accuracy for subject {test_subject}: {accuracy:.4f}\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        results = []\n",
    "        for idx, (image_path, feature, pred_class, actual_class) in enumerate(zip(\n",
    "            test_df['Filename'], test_features, predicted_classes, actual_classes)):\n",
    "            results.append({\n",
    "                'Subject': test_subject,\n",
    "                'Test Accuracy': accuracy,\n",
    "                'Test Loss': loss,\n",
    "                'Image File': image_path,\n",
    "                'Feature': feature.tolist(),\n",
    "                'Predicted Class': pred_class,\n",
    "                'Actual Class': actual_class\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(csv_path, f\"1127_results_{test_subject}.csv\"), index=False, encoding='utf-8')\n",
    "        print(f\"Results for subject {test_subject} saved.\")\n",
    "        \n",
    "        # 모델 저장\n",
    "        model_save_path = os.path.join(csv_path, f\"1127_model_{test_subject}.h5\")\n",
    "        combined_model.save(model_save_path)\n",
    "        print(f\"Model saved at: {model_save_path}\")\n",
    "    \n",
    "    print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "# 데이터 경로\n",
    "folder_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\img\"\n",
    "csv_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\"\n",
    "test_subjects = ['lgj', 'hsb', 'scy']  # 테스트로 사용할 대상\n",
    "\n",
    "# LOSO 수행\n",
    "train_and_evaluate(folder_path, csv_path, valid_labels, test_subjects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
