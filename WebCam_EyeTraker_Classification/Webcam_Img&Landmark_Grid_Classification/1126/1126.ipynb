{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b24a7c-fce2-4a99-97b9-9b7264e9be7b",
   "metadata": {},
   "source": [
    "일단 1125_test_hsh를 진행한 결과 학습이 제대로 이루어지지 않음\n",
    "고로 계층의 깊이가 너무 깊었기 때문에 생기는 문제점, 흑백 사진으로 인한 동공 이미지 사진의 정보를 잃었을 가능성 때문이라고 판단해\n",
    "resnet50 -> resnet18 로 진행, 그리고 grayscale -> rgb로 그대로 사용할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2087f891-e7ad-445f-93e0-01e4b1ae50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on subject: hsh\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_65', 'keras_tensor_130']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 157ms/step - accuracy: 0.1860 - loss: 2.6892 - val_accuracy: 0.1000 - val_loss: 2.9397\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.6300 - loss: 0.9870 - val_accuracy: 0.2077 - val_loss: 6.1664\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.8040 - loss: 0.5774 - val_accuracy: 0.2615 - val_loss: 6.6334\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 154ms/step - accuracy: 0.8614 - loss: 0.4520 - val_accuracy: 0.0538 - val_loss: 9.5488\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 153ms/step - accuracy: 0.8885 - loss: 0.3158 - val_accuracy: 0.1354 - val_loss: 16.8776\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 153ms/step - accuracy: 0.9146 - loss: 0.2688 - val_accuracy: 0.1969 - val_loss: 8.0665\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9270 - loss: 0.2480 - val_accuracy: 0.2631 - val_loss: 16.1317\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 159ms/step - accuracy: 0.9410 - loss: 0.1777 - val_accuracy: 0.2892 - val_loss: 7.9822\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9308 - loss: 0.2301 - val_accuracy: 0.1415 - val_loss: 13.7402\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.9411 - loss: 0.1960 - val_accuracy: 0.1938 - val_loss: 9.3891\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 163ms/step - accuracy: 0.9455 - loss: 0.1807 - val_accuracy: 0.1969 - val_loss: 13.1457\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.9376 - loss: 0.2669 - val_accuracy: 0.1892 - val_loss: 36.6876\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.9476 - loss: 0.1899 - val_accuracy: 0.1815 - val_loss: 22.9302\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.9708 - loss: 0.1184 - val_accuracy: 0.1231 - val_loss: 33.2035\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.9572 - loss: 0.1601 - val_accuracy: 0.2169 - val_loss: 27.2645\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.9583 - loss: 0.1553 - val_accuracy: 0.2323 - val_loss: 22.1008\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 161ms/step - accuracy: 0.9795 - loss: 0.1057 - val_accuracy: 0.2323 - val_loss: 20.0218\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 161ms/step - accuracy: 0.9571 - loss: 0.1346 - val_accuracy: 0.2508 - val_loss: 32.9741\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 161ms/step - accuracy: 0.9730 - loss: 0.0884 - val_accuracy: 0.2231 - val_loss: 25.5115\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 161ms/step - accuracy: 0.9631 - loss: 0.1756 - val_accuracy: 0.3015 - val_loss: 18.1979\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 161ms/step - accuracy: 0.9783 - loss: 0.0926 - val_accuracy: 0.1708 - val_loss: 26.8794\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 161ms/step - accuracy: 0.9705 - loss: 0.1344 - val_accuracy: 0.2169 - val_loss: 22.9797\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 161ms/step - accuracy: 0.9666 - loss: 0.1218 - val_accuracy: 0.2631 - val_loss: 26.7216\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 161ms/step - accuracy: 0.9729 - loss: 0.1263 - val_accuracy: 0.2138 - val_loss: 33.6572\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9792 - loss: 0.0911 - val_accuracy: 0.2954 - val_loss: 23.0257\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 161ms/step - accuracy: 0.9779 - loss: 0.1160 - val_accuracy: 0.1169 - val_loss: 53.0110\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 161ms/step - accuracy: 0.9739 - loss: 0.1262 - val_accuracy: 0.2000 - val_loss: 35.9810\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9814 - loss: 0.0888 - val_accuracy: 0.1831 - val_loss: 41.4980\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 162ms/step - accuracy: 0.9720 - loss: 0.1118 - val_accuracy: 0.3123 - val_loss: 17.7671\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9739 - loss: 0.1492 - val_accuracy: 0.2754 - val_loss: 15.0729\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9853 - loss: 0.0568 - val_accuracy: 0.2338 - val_loss: 23.1625\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9682 - loss: 0.1797 - val_accuracy: 0.2200 - val_loss: 19.3205\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9750 - loss: 0.1555 - val_accuracy: 0.2877 - val_loss: 11.6023\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9794 - loss: 0.1095 - val_accuracy: 0.1969 - val_loss: 19.6694\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9831 - loss: 0.0692 - val_accuracy: 0.1754 - val_loss: 29.6618\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9856 - loss: 0.0631 - val_accuracy: 0.2646 - val_loss: 23.9640\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9716 - loss: 0.1171 - val_accuracy: 0.1492 - val_loss: 19.8023\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9771 - loss: 0.0881 - val_accuracy: 0.1831 - val_loss: 26.2526\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9842 - loss: 0.0924 - val_accuracy: 0.3031 - val_loss: 13.2183\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9880 - loss: 0.0649 - val_accuracy: 0.0862 - val_loss: 45.9100\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9832 - loss: 0.0687 - val_accuracy: 0.1969 - val_loss: 42.5017\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9836 - loss: 0.1044 - val_accuracy: 0.2015 - val_loss: 37.4389\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9744 - loss: 0.1386 - val_accuracy: 0.2769 - val_loss: 23.0471\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9703 - loss: 0.1361 - val_accuracy: 0.1400 - val_loss: 28.1570\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9952 - loss: 0.0269 - val_accuracy: 0.1108 - val_loss: 21.1970\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9844 - loss: 0.0987 - val_accuracy: 0.3138 - val_loss: 14.8091\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9737 - loss: 0.1108 - val_accuracy: 0.2246 - val_loss: 19.5363\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9811 - loss: 0.0815 - val_accuracy: 0.2369 - val_loss: 22.2835\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9888 - loss: 0.0558 - val_accuracy: 0.2062 - val_loss: 28.8865\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9774 - loss: 0.1031 - val_accuracy: 0.2308 - val_loss: 29.9379\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.2488 - loss: 28.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject hsh: 0.2308\n",
      "Results for subject hsh saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\model_hsh.h5\n",
      "Testing on subject: hyh\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_139', 'keras_tensor_204', 'keras_tensor_269']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 160ms/step - accuracy: 0.2281 - loss: 2.6586 - val_accuracy: 0.5492 - val_loss: 1.3062\n",
      "Epoch 2/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 159ms/step - accuracy: 0.6249 - loss: 1.0113 - val_accuracy: 0.3892 - val_loss: 2.2551\n",
      "Epoch 3/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.7936 - loss: 0.5272 - val_accuracy: 0.5815 - val_loss: 2.9172\n",
      "Epoch 4/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.8874 - loss: 0.3408 - val_accuracy: 0.4862 - val_loss: 2.8219\n",
      "Epoch 5/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 159ms/step - accuracy: 0.9053 - loss: 0.2949 - val_accuracy: 0.5292 - val_loss: 2.2479\n",
      "Epoch 6/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9237 - loss: 0.2684 - val_accuracy: 0.5923 - val_loss: 1.7755\n",
      "Epoch 7/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9350 - loss: 0.2121 - val_accuracy: 0.4985 - val_loss: 2.6425\n",
      "Epoch 8/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9357 - loss: 0.2098 - val_accuracy: 0.4492 - val_loss: 4.8930\n",
      "Epoch 9/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 159ms/step - accuracy: 0.9509 - loss: 0.1696 - val_accuracy: 0.5138 - val_loss: 3.6314\n",
      "Epoch 10/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9517 - loss: 0.1714 - val_accuracy: 0.4400 - val_loss: 8.1285\n",
      "Epoch 11/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9514 - loss: 0.1764 - val_accuracy: 0.2308 - val_loss: 20.5310\n",
      "Epoch 12/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9601 - loss: 0.1098 - val_accuracy: 0.3815 - val_loss: 7.3035\n",
      "Epoch 13/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9589 - loss: 0.1622 - val_accuracy: 0.5815 - val_loss: 5.4685\n",
      "Epoch 14/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9681 - loss: 0.1428 - val_accuracy: 0.5200 - val_loss: 7.2002\n",
      "Epoch 15/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9680 - loss: 0.1208 - val_accuracy: 0.5200 - val_loss: 6.9438\n",
      "Epoch 16/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9626 - loss: 0.1706 - val_accuracy: 0.4846 - val_loss: 5.6194\n",
      "Epoch 17/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 160ms/step - accuracy: 0.9704 - loss: 0.1201 - val_accuracy: 0.2985 - val_loss: 18.1908\n",
      "Epoch 18/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 161ms/step - accuracy: 0.9549 - loss: 0.1936 - val_accuracy: 0.4831 - val_loss: 3.8477\n",
      "Epoch 19/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 161ms/step - accuracy: 0.9761 - loss: 0.1051 - val_accuracy: 0.4185 - val_loss: 10.4323\n",
      "Epoch 20/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 161ms/step - accuracy: 0.9854 - loss: 0.0667 - val_accuracy: 0.4954 - val_loss: 7.6095\n",
      "Epoch 21/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 161ms/step - accuracy: 0.9528 - loss: 0.2437 - val_accuracy: 0.3754 - val_loss: 14.8308\n",
      "Epoch 22/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 160ms/step - accuracy: 0.9705 - loss: 0.0959 - val_accuracy: 0.2415 - val_loss: 94.8290\n",
      "Epoch 23/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 161ms/step - accuracy: 0.9775 - loss: 0.1199 - val_accuracy: 0.3323 - val_loss: 32.5877\n",
      "Epoch 24/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 156ms/step - accuracy: 0.9810 - loss: 0.0737 - val_accuracy: 0.1800 - val_loss: 85.3466\n",
      "Epoch 25/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9772 - loss: 0.1070 - val_accuracy: 0.4215 - val_loss: 12.1091\n",
      "Epoch 26/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 157ms/step - accuracy: 0.9766 - loss: 0.1225 - val_accuracy: 0.2585 - val_loss: 23.6619\n",
      "Epoch 27/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9812 - loss: 0.0610 - val_accuracy: 0.0769 - val_loss: 204.9757\n",
      "Epoch 28/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9676 - loss: 0.1235 - val_accuracy: 0.2492 - val_loss: 45.3607\n",
      "Epoch 29/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 157ms/step - accuracy: 0.9924 - loss: 0.0345 - val_accuracy: 0.1800 - val_loss: 151.4164\n",
      "Epoch 30/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9667 - loss: 0.1261 - val_accuracy: 0.1385 - val_loss: 137.9594\n",
      "Epoch 31/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9834 - loss: 0.0750 - val_accuracy: 0.1892 - val_loss: 67.5552\n",
      "Epoch 32/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 157ms/step - accuracy: 0.9863 - loss: 0.0648 - val_accuracy: 0.2954 - val_loss: 35.3805\n",
      "Epoch 33/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 158ms/step - accuracy: 0.9658 - loss: 0.1700 - val_accuracy: 0.2631 - val_loss: 40.2567\n",
      "Epoch 34/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 158ms/step - accuracy: 0.9924 - loss: 0.0298 - val_accuracy: 0.2600 - val_loss: 41.3551\n",
      "Epoch 35/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 158ms/step - accuracy: 0.9781 - loss: 0.1274 - val_accuracy: 0.2108 - val_loss: 77.4783\n",
      "Epoch 36/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 158ms/step - accuracy: 0.9830 - loss: 0.0928 - val_accuracy: 0.2477 - val_loss: 53.4516\n",
      "Epoch 37/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 162ms/step - accuracy: 0.9819 - loss: 0.0798 - val_accuracy: 0.2585 - val_loss: 35.2482\n",
      "Epoch 38/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 164ms/step - accuracy: 0.9683 - loss: 0.1811 - val_accuracy: 0.3538 - val_loss: 14.8247\n",
      "Epoch 39/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 163ms/step - accuracy: 0.9952 - loss: 0.0290 - val_accuracy: 0.5431 - val_loss: 6.2691\n",
      "Epoch 40/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 163ms/step - accuracy: 0.9811 - loss: 0.1045 - val_accuracy: 0.2723 - val_loss: 75.1073\n",
      "Epoch 41/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 163ms/step - accuracy: 0.9778 - loss: 0.1107 - val_accuracy: 0.2123 - val_loss: 137.8297\n",
      "Epoch 42/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 162ms/step - accuracy: 0.9972 - loss: 0.0168 - val_accuracy: 0.2292 - val_loss: 169.7536\n",
      "Epoch 43/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 163ms/step - accuracy: 0.9672 - loss: 0.1684 - val_accuracy: 0.2477 - val_loss: 30.9090\n",
      "Epoch 44/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 162ms/step - accuracy: 0.9823 - loss: 0.0858 - val_accuracy: 0.5338 - val_loss: 7.0163\n",
      "Epoch 45/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 158ms/step - accuracy: 0.9853 - loss: 0.0564 - val_accuracy: 0.4138 - val_loss: 8.5389\n",
      "Epoch 46/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 158ms/step - accuracy: 0.9862 - loss: 0.0483 - val_accuracy: 0.2123 - val_loss: 47.2570\n",
      "Epoch 47/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9970 - loss: 0.0220 - val_accuracy: 0.2969 - val_loss: 28.6738\n",
      "Epoch 48/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 159ms/step - accuracy: 0.9870 - loss: 0.0635 - val_accuracy: 0.2862 - val_loss: 81.1411\n",
      "Epoch 49/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9715 - loss: 0.1824 - val_accuracy: 0.2569 - val_loss: 46.7090\n",
      "Epoch 50/50\n",
      "\u001b[1m2600/2600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 160ms/step - accuracy: 0.9865 - loss: 0.0865 - val_accuracy: 0.3538 - val_loss: 18.2866\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.3435 - loss: 19.4322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for subject hyh: 0.3538\n",
      "Results for subject hyh saved.\n",
      "Model saved at: C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\model_hyh.h5\n",
      "Average Accuracy: 0.2923\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "# Mish activation function\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    image = load_img(image_path, color_mode='rgb', target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "# 파일 이름에서 session과 point 추출\n",
    "def extract_session_and_point(filename):\n",
    "    session_match = re.search(r'img_(\\d+)', filename)\n",
    "    point_match = re.search(r'\\((\\d+)\\)', filename)\n",
    "    session = int(session_match.group(1)) if session_match else None\n",
    "    point = int(point_match.group(1)) if point_match else None\n",
    "    return session, point\n",
    "\n",
    "# ResNet18 모델 생성\n",
    "def create_resnet18_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    filter_sizes = [64, 128, 256, 512]\n",
    "    num_blocks = [2, 2, 2, 2]\n",
    "    for filters, blocks in zip(filter_sizes, num_blocks):\n",
    "        for i in range(blocks):\n",
    "            x = resnet_block(x, filters, downsample=(i == 0 and filters != 64))\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# ResNet 블록 생성\n",
    "def resnet_block(x, filters, downsample=False):\n",
    "    shortcut = x\n",
    "    strides = (2, 2) if downsample else (1, 1)\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation(mish)(x)\n",
    "    return x\n",
    "\n",
    "# MLP 모델 생성\n",
    "def create_mlp_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation=mish)(input_layer)\n",
    "    x = layers.Dense(64, activation=mish)(x)\n",
    "    x = layers.Dense(3, activation=mish)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# 유효한 라벨 정의\n",
    "valid_labels = [1, 5, 9, 12, 16, 19, 23, 27, 30, 34, 37, 41, 45]\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "def prepare_data(folder_path, csv_path, test_subject, valid_labels):\n",
    "    subject_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "    train_subjects = [s for s in subject_folders if s != test_subject]\n",
    "    \n",
    "    # 학습 데이터 로드\n",
    "    train_images, train_csv_data = [], pd.DataFrame()\n",
    "    for train_subject in train_subjects:\n",
    "        train_folder = os.path.join(folder_path, train_subject)\n",
    "        train_csv = os.path.join(csv_path, f\"{train_subject}.csv\")\n",
    "        train_images.extend(glob.glob(os.path.join(train_folder, '*.jpg')))\n",
    "        if os.path.exists(train_csv):\n",
    "            train_csv_data = pd.concat([train_csv_data, pd.read_csv(train_csv)])\n",
    "    train_csv_data.rename(columns={'session': 'Session', 'point': 'Point'}, inplace=True)\n",
    "    \n",
    "    # 테스트 데이터 로드\n",
    "    test_folder = os.path.join(folder_path, test_subject)\n",
    "    test_csv = os.path.join(csv_path, f\"{test_subject}.csv\")\n",
    "    test_images = glob.glob(os.path.join(test_folder, '*.jpg'))\n",
    "    test_csv_data = pd.read_csv(test_csv) if os.path.exists(test_csv) else pd.DataFrame(columns=['Session', 'Point'])\n",
    "    test_csv_data.rename(columns={'session': 'Session', 'point': 'Point'}, inplace=True)\n",
    "    \n",
    "    # 데이터 처리 함수\n",
    "    def process_images(image_paths, csv_data, valid_labels):\n",
    "        image_data = []\n",
    "        for img in image_paths:\n",
    "            session, point = extract_session_and_point(os.path.basename(img))\n",
    "            if point in valid_labels:\n",
    "                subject_name = os.path.basename(os.path.dirname(img))\n",
    "                unique_filename = f\"{subject_name}_{os.path.basename(img)}\"\n",
    "                image_data.append({\n",
    "                    'Filename': os.path.abspath(img),\n",
    "                    'UniqueFilename': unique_filename,\n",
    "                    'Session': session,\n",
    "                    'Point': point\n",
    "                })\n",
    "        df = pd.DataFrame(image_data)\n",
    "        merged = pd.merge(df, csv_data, on=['Session', 'Point'], how='inner')\n",
    "        merged = merged.drop_duplicates(subset=['UniqueFilename', 'Session', 'Point'])\n",
    "        merged = merged[merged['Point'].isin(valid_labels)]\n",
    "        return merged\n",
    "    \n",
    "    train_df = process_images(train_images, train_csv_data, valid_labels)\n",
    "    test_df = process_images(test_images, test_csv_data, valid_labels)\n",
    "    return train_df, test_df\n",
    "\n",
    "# 모델 훈련 및 평가\n",
    "def train_and_evaluate(folder_path, csv_path, valid_labels, test_subjects):\n",
    "    accuracies = []\n",
    "    for test_subject in test_subjects:\n",
    "        print(f\"Testing on subject: {test_subject}\")\n",
    "        train_df, test_df = prepare_data(folder_path, csv_path, test_subject, valid_labels)\n",
    "        \n",
    "        train_images_array = np.array([load_and_preprocess_image(path) for path in train_df['Filename']])\n",
    "        train_features = train_df.drop(['Filename', 'UniqueFilename', 'Session', 'Point'], axis=1).values\n",
    "        train_labels = train_df['Point'].map({label: idx for idx, label in enumerate(valid_labels)}).values\n",
    "        train_labels = to_categorical(train_labels, num_classes=len(valid_labels))\n",
    "        \n",
    "        test_images_array = np.array([load_and_preprocess_image(path) for path in test_df['Filename']])\n",
    "        test_features = test_df.drop(['Filename', 'UniqueFilename', 'Session', 'Point'], axis=1).values\n",
    "        test_labels = test_df['Point'].map({label: idx for idx, label in enumerate(valid_labels)}).values\n",
    "        test_labels = to_categorical(test_labels, num_classes=len(valid_labels))\n",
    "        \n",
    "        right_eye_model = create_resnet18_model((128, 128, 3))\n",
    "        left_eye_model = create_resnet18_model((128, 128, 3))\n",
    "        mlp_model = create_mlp_model(train_features.shape[1:])\n",
    "        combined_input = layers.concatenate([right_eye_model.output, left_eye_model.output, mlp_model.output])\n",
    "        x = layers.Dense(256, activation=mish)(combined_input)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        output_layer = layers.Dense(len(valid_labels), activation='softmax')(x)\n",
    "        combined_model = Model(inputs=[right_eye_model.input, left_eye_model.input, mlp_model.input], outputs=output_layer)\n",
    "\n",
    "        combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = combined_model.fit(\n",
    "            [train_images_array, train_images_array, train_features], train_labels,\n",
    "            validation_data=([test_images_array, test_images_array, test_features], test_labels),\n",
    "            epochs=50,\n",
    "            batch_size=1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        predictions = combined_model.predict([test_images_array, test_images_array, test_features])\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        actual_classes = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        loss, accuracy = combined_model.evaluate([test_images_array, test_images_array, test_features], test_labels)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Testing accuracy for subject {test_subject}: {accuracy:.4f}\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        results = []\n",
    "        for idx, (image_path, feature, pred_class, actual_class) in enumerate(zip(\n",
    "            test_df['Filename'], test_features, predicted_classes, actual_classes)):\n",
    "            results.append({\n",
    "                'Subject': test_subject,\n",
    "                'Test Accuracy': accuracy,\n",
    "                'Test Loss': loss,\n",
    "                'Image File': image_path,\n",
    "                'Feature': feature.tolist(),\n",
    "                'Predicted Class': pred_class,\n",
    "                'Actual Class': actual_class\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(csv_path, f\"results_{test_subject}.csv\"), index=False, encoding='utf-8')\n",
    "        print(f\"Results for subject {test_subject} saved.\")\n",
    "        \n",
    "        # 모델 저장\n",
    "        model_save_path = os.path.join(csv_path, f\"model_{test_subject}.h5\")\n",
    "        combined_model.save(model_save_path)\n",
    "        print(f\"Model saved at: {model_save_path}\")\n",
    "    \n",
    "    print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "# 데이터 경로\n",
    "folder_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\img\"\n",
    "csv_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\"\n",
    "test_subjects = ['hsh', 'hyh']  # 테스트로 사용할 대상\n",
    "\n",
    "# LOSO 수행\n",
    "train_and_evaluate(folder_path, csv_path, valid_labels, test_subjects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
