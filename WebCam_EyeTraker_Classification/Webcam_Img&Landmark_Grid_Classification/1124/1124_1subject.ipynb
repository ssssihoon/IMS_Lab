{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56df7881-b465-4ad2-ae7a-bbb791be8d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\sihoon\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_1744', 'keras_tensor_1914', 'keras_tensor_2084']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 350ms/step - accuracy: 0.0556 - loss: 7.4956 - val_accuracy: 0.0435 - val_loss: 3.5182\n",
      "Epoch 2/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 348ms/step - accuracy: 0.0383 - loss: 3.2104 - val_accuracy: 0.0261 - val_loss: 3.3418\n",
      "Epoch 3/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0590 - loss: 3.1922 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 4/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 349ms/step - accuracy: 0.0536 - loss: 3.1382 - val_accuracy: 0.0435 - val_loss: 3.1401\n",
      "Epoch 5/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0471 - loss: 3.1396 - val_accuracy: 0.0000e+00 - val_loss: 3.1343\n",
      "Epoch 6/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0405 - loss: 3.1957 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 7/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0501 - loss: 3.1596 - val_accuracy: 0.0522 - val_loss: 3.1277\n",
      "Epoch 8/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0260 - loss: 3.1365 - val_accuracy: 0.0522 - val_loss: 3.1325\n",
      "Epoch 9/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0361 - loss: 3.1381 - val_accuracy: 0.0957 - val_loss: 3.0573\n",
      "Epoch 10/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0420 - loss: 3.1699 - val_accuracy: 0.0435 - val_loss: 3.6569\n",
      "Epoch 11/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0461 - loss: 3.1819 - val_accuracy: 0.0000e+00 - val_loss: 8.6540\n",
      "Epoch 12/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0324 - loss: 3.1425 - val_accuracy: 0.0522 - val_loss: 3.1368\n",
      "Epoch 13/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0358 - loss: 3.1372 - val_accuracy: 0.0435 - val_loss: 3.1494\n",
      "Epoch 14/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0547 - loss: 3.1413 - val_accuracy: 0.0783 - val_loss: 3.1365\n",
      "Epoch 15/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0300 - loss: 3.1359 - val_accuracy: 0.0870 - val_loss: 3.1233\n",
      "Epoch 16/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0418 - loss: 3.1387 - val_accuracy: 0.0348 - val_loss: 3.1458\n",
      "Epoch 17/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0604 - loss: 3.1359 - val_accuracy: 0.0435 - val_loss: 3.1492\n",
      "Epoch 18/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0422 - loss: 3.1365 - val_accuracy: 0.0348 - val_loss: 3.1466\n",
      "Epoch 19/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0369 - loss: 3.1366 - val_accuracy: 0.0522 - val_loss: 3.1467\n",
      "Epoch 20/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0131 - loss: 3.1372 - val_accuracy: 0.0348 - val_loss: 3.1500\n",
      "Epoch 21/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0362 - loss: 3.1365 - val_accuracy: 0.0348 - val_loss: 3.1483\n",
      "Epoch 22/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 350ms/step - accuracy: 0.0441 - loss: 3.1594 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 23/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 352ms/step - accuracy: 0.0511 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 24/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0354 - loss: 3.1369 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 25/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 352ms/step - accuracy: 0.0364 - loss: 3.1371 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 26/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0296 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 27/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0379 - loss: 3.1367 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 28/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0256 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 29/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0577 - loss: 3.1362 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 30/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0183 - loss: 3.1368 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 31/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0183 - loss: 3.1367 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 32/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 352ms/step - accuracy: 0.0312 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 33/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0595 - loss: 3.1365 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 34/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0525 - loss: 3.1363 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 35/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 353ms/step - accuracy: 0.0180 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 36/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0403 - loss: 3.1368 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 37/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0550 - loss: 3.1367 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 38/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0329 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 39/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0447 - loss: 3.1367 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 40/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0240 - loss: 3.1363 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 41/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0269 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 42/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0125 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 43/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 351ms/step - accuracy: 0.0140 - loss: 3.1367 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 44/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 352ms/step - accuracy: 0.0232 - loss: 3.1365 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 45/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0160 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 46/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 351ms/step - accuracy: 0.0413 - loss: 3.1368 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 47/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 352ms/step - accuracy: 0.0171 - loss: 3.1366 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 48/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 354ms/step - accuracy: 0.0196 - loss: 3.1365 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 49/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 358ms/step - accuracy: 0.0436 - loss: 3.1368 - val_accuracy: 0.0435 - val_loss: 3.1355\n",
      "Epoch 50/50\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 348ms/step - accuracy: 0.0533 - loss: 3.1364 - val_accuracy: 0.0435 - val_loss: 3.1355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.021739130839705467, Validation Accuracy: 0.043478261679410934\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 135\u001b[0m\n\u001b[0;32m    132\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(model_save_folder)\n\u001b[0;32m    133\u001b[0m combined_model\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_save_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 135\u001b[0m predictions \u001b[38;5;241m=\u001b[39m combined_model\u001b[38;5;241m.\u001b[39mpredict([right_images_array, left_images_array, features_array])\n\u001b[0;32m    136\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    137\u001b[0m actual_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features_array' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "# Mish activation function\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    image = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "def extract_session_and_point(filename):\n",
    "    session_match = re.search(r'img_(\\d+)', filename)\n",
    "    point_match = re.search(r'\\((\\d+)\\)', filename)\n",
    "    session = int(session_match.group(1)) if session_match else None\n",
    "    point = int(point_match.group(1)) if point_match else None\n",
    "    return session, point\n",
    "\n",
    "# 병목 구조\n",
    "def bottleneck_block(x, filters, downsample=False):\n",
    "    shortcut = x\n",
    "    strides = (2, 2) if downsample else (1, 1)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters * 4, kernel_size=(1, 1), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if downsample or shortcut.shape[-1] != filters * 4:\n",
    "        shortcut = layers.Conv2D(filters * 4, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n",
    "    \n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation(mish)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# ResNet-50\n",
    "def create_resnet50_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(mish)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    filter_sizes = [64, 128, 256, 512]\n",
    "    num_blocks = [3, 4, 6, 3]  # ResNet-50에서 각 블록별 반복 횟수\n",
    "    for filters, blocks in zip(filter_sizes, num_blocks):\n",
    "        for i in range(blocks):\n",
    "            x = bottleneck_block(x, filters, downsample=(i == 0 and filters != 64))\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# MLP\n",
    "def create_mlp_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation = mish)(input_layer)\n",
    "    x = layers.Dense(64, activation = mish)(x)\n",
    "    x = layers.Dense(3, activation = mish)(x) # 나중에 3 -> 2로 수정 예정. (3으로 인한 특징 추출{가설}을 파악하기 위함)\n",
    "    x = layers.Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs= x)\n",
    "\n",
    "folder_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\img\\hsh\"\n",
    "csv_path = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\results\\hsh.csv\"\n",
    "\n",
    "csv_data = pd.read_csv(csv_path, header=0, encoding='utf-8')\n",
    "\n",
    "# 이미지 파일 읽기 및 session/point 추출\n",
    "image_files = glob.glob(os.path.join(folder_path, '*.jpg'))\n",
    "image_data = []\n",
    "for file in image_files:\n",
    "    session, point = extract_session_and_point(os.path.basename(file))\n",
    "    if session is not None and point is not None:\n",
    "        image_data.append({'Filename': file, 'Session': session, 'Point': point})\n",
    "image_df = pd.DataFrame(image_data)\n",
    "\n",
    "merged_data = pd.merge(image_df, csv_data, left_on=['Session', 'Point'], right_on=['session', 'point'], how='inner')\n",
    "\n",
    "valid_labels = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45]\n",
    "filtered_data = merged_data[merged_data['Point'].isin(valid_labels)]\n",
    "\n",
    "right_images = filtered_data[filtered_data['Filename'].str.contains('right', case=False)]\n",
    "left_images = filtered_data[filtered_data['Filename'].str.contains('left', case=False)]\n",
    "\n",
    "right_images_array = np.array([load_and_preprocess_image(path) for path in right_images['Filename']])\n",
    "left_images_array = np.array([load_and_preprocess_image(path) for path in left_images['Filename']])\n",
    "\n",
    "features = filtered_data.drop(['Filename', 'session', 'point', 'Session', 'Point'], axis=1).values\n",
    "labels = filtered_data['Point'].map({label: idx for idx, label in enumerate(valid_labels)}).values\n",
    "labels = to_categorical(labels, num_classes=len(valid_labels))\n",
    "\n",
    "right_eye_model = create_resnet50_model((128, 128, 1))\n",
    "left_eye_model = create_resnet50_model((128, 128, 1))\n",
    "mlp_model = create_mlp_model(features.shape[1:])\n",
    "\n",
    "combined_input = layers.concatenate([right_eye_model.output, left_eye_model.output, mlp_model.output])\n",
    "\n",
    "x = layers.Dense(256, activation=mish)(combined_input)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output_layer = layers.Dense(len(valid_labels), activation='softmax')(x)\n",
    "\n",
    "combined_model = Model(inputs=[right_eye_model.input, left_eye_model.input, mlp_model.input], outputs=output_layer)\n",
    "\n",
    "combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = combined_model.fit([right_images_array, left_images_array, features], labels, \n",
    "                             epochs=50, batch_size=1, validation_split=0.2)\n",
    "\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "model_save_folder = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\result\\1124\"\n",
    "if not os.path.exists(model_save_folder):\n",
    "    os.makedirs(model_save_folder)\n",
    "combined_model.save(os.path.join(model_save_folder, \"combined_model.h5\"))\n",
    "\n",
    "predictions = combined_model.predict([right_images_array, left_images_array, features])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "actual_classes = np.argmax(labels, axis=1)\n",
    "\n",
    "incorrect_predictions = np.where(actual_classes != predicted_classes)[0]\n",
    "\n",
    "data = {\n",
    "    'Right Image': [os.path.basename(right_images[idx]) for idx in range(len(right_images))],\n",
    "    'Left Image': [os.path.basename(left_images[idx]) for idx in range(len(left_images))],\n",
    "    'Actual Class': actual_classes.tolist(),\n",
    "    'Predicted Class': predicted_classes.tolist(),\n",
    "    'Features': [features_array[idx].tolist() for idx in range(len(features_array))]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "csv_save_folder = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\result\\1124\"\n",
    "if not os.path.exists(csv_save_folder):\n",
    "    os.makedirs(csv_save_folder)\n",
    "df.to_csv(os.path.join(csv_save_folder, \"predictions.csv\"), index=False)\n",
    "\n",
    "# 잘못 예측한 데이터만 저장\n",
    "data = {\n",
    "    'Right Image': [os.path.basename(right_images[idx]) for idx in incorrect_predictions],\n",
    "    'Left Image': [os.path.basename(left_images[idx]) for idx in incorrect_predictions],\n",
    "    'Actual Class': actual_classes[incorrect_predictions],\n",
    "    'Predicted Class': predicted_classes[incorrect_predictions],\n",
    "    'Features': [features_array[idx].tolist() for idx in incorrect_predictions]\n",
    "}\n",
    "df_incorrect = pd.DataFrame(data)\n",
    "\n",
    "# 잘못 예측한 데이터를 저장할 CSV 경로\n",
    "incorrect_csv_save_folder = r\"C:\\Users\\admin\\Desktop\\sihoon\\webcam\\result\\1124\"\n",
    "if not os.path.exists(incorrect_csv_save_folder):\n",
    "    os.makedirs(incorrect_csv_save_folder)\n",
    "\n",
    "incorrect_csv_path = os.path.join(incorrect_csv_save_folder, \"incorrect_predictions.csv\")\n",
    "df_incorrect.to_csv(incorrect_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
