{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59c6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_data = \"C:\\\\Users\\\\IMS\\Desktop\\\\Hwangsihoon\\\\WebCam\\\\participant_data.json\"\n",
    "\n",
    "with open(json_data, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# user_name 초기화를 위한 빈 리스트 생성\n",
    "records = []\n",
    "\n",
    "# 각 user_name에 대해 meta 정보와 dot_info 정보 추출 및 데이터프레임 생성\n",
    "for user_name, user_data in data.items():\n",
    "    meta_info = user_data[\"meta\"]\n",
    "    dot_info = user_data[\"dot_info\"]\n",
    "    for n_key, n_value in dot_info.items():\n",
    "        for m_key, m_value in n_value.items():\n",
    "            # 각 dot_info 항목에 meta 정보 및 user_name 추가, n, m_key : 파일명 -> User_n_m\n",
    "            combined_data = {**meta_info, **m_value, \"user_name\": user_name, \"n_key\": n_key, \"m_key\": m_key}\n",
    "            records.append(combined_data)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 왼쪽, 오른쪽 눈 df화\n",
    "df_right = df[['user_name', 'file_name_right', 'right_landmarks', 'label']]\n",
    "df_left = df[['user_name', 'file_name_left', 'left_landmarks', 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739e3001",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ea047d29dc2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# First & Sceond Inpput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mright_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mright_images\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mleft_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mleft_images\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ea047d29dc2e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# First & Sceond Inpput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mright_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mright_images\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mleft_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mleft_images\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ea047d29dc2e>\u001b[0m in \u001b[0;36mload_and_preprocess_image\u001b[1;34m(image_path, target_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mimage_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mimage_array\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emg\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emg\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;31m# but original PIL image has format (width, height, channel)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emg\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emg\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m             \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emg\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emg\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\IMS\\\\Desktop\\\\Hwangsihoon\\\\WebCam\\img\"\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, '*.jpg'))\n",
    "\n",
    "# right파일, left파일 각각 분리\n",
    "right_images = [file for file in files if 'right' in os.path.basename(file).lower()]\n",
    "left_images = [file for file in files if 'left' in os.path.basename(file).lower()]\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    return image_array\n",
    "\n",
    "\n",
    "# First & Sceond Inpput\n",
    "right_images = [load_and_preprocess_image(img_path) for img_path in right_images]\n",
    "left_images = [load_and_preprocess_image(img_path) for img_path in left_images]\n",
    "\n",
    "# Labels\n",
    "right_labels = np.array(df_right['label'].tolist())\n",
    "left_labels = np.array(df_left['label'].tolist())\n",
    "\n",
    "labels = right_labels\n",
    "\n",
    "\n",
    "print(right_labels[0])\n",
    "print(left_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fd6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Input\n",
    "def expand_landmarks(landmarks):\n",
    "    if len(landmarks) == 2:\n",
    "        return pd.Series({\n",
    "            'x1': landmarks[0][0],\n",
    "            'y1': landmarks[0][1],\n",
    "            'x2': landmarks[1][0],\n",
    "            'y2': landmarks[1][1]\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "# LandMark\n",
    "right_landmark = df_right['right_landmarks']\n",
    "left_landmark = df_left['left_landmarks']\n",
    "\n",
    "right_landmarks_expanded = df_right['right_landmarks'].apply(expand_landmarks)\n",
    "left_landmarks_expanded = df_left['left_landmarks'].apply(expand_landmarks)\n",
    "\n",
    "expanded_landmarks_combined = pd.concat([right_landmarks_expanded.add_suffix('_right'), left_landmarks_expanded.add_suffix('_left')], axis=1)\n",
    "landmark = np.array(expanded_landmarks_combined)\n",
    "landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7af558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "right_images_train, right_images_test, left_images_train, left_images_test, labels_train, labels_test, landmark_train, landmark_test = train_test_split(\n",
    "    right_images, left_images, right_labels, landmark, test_size=0.4, shuffle=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1cc4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, Model, Input\n",
    "\n",
    "x1 = right_images  # 이미지\n",
    "x2 = left_images\n",
    "x3 = landmark\n",
    "\n",
    "y1 = labels  # 레이블\n",
    "y2 = labels\n",
    "\n",
    "# input1 모델\n",
    "input1 = Input(shape=(128, 128, 3))\n",
    "x1 = layers.Conv2D(32, kernel_size=(7, 7), activation='relu', padding='same')(input1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "x1 = layers.Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "x1 = layers.Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "x1 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "# x1 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x1)\n",
    "# x1 = layers.BatchNormalization()(x1)\n",
    "# x1 = layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "\n",
    "x1 = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(x1)\n",
    "x1 = layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "\n",
    "x1 = layers.Flatten()(x1)  # Flatten 레이어\n",
    "#x1 = layers.Dense(128, activation='relu')(x1)\n",
    "\n",
    "# input2 모델\n",
    "input2 = Input(shape=(128, 128, 3))\n",
    "x2 = layers.Conv2D(32, kernel_size=(7, 7), activation='relu', padding='same')(input2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "x2 = layers.Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "x2 = layers.Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "x2 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "# x2 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x2)\n",
    "# x2 = layers.BatchNormalization()(x2)\n",
    "# x2 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "x2 = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "\n",
    "x2 = layers.Flatten()(x2)  # Flatten 레이어\n",
    "#x2 = layers.Dense(128, activation='relu')(x2)\n",
    "\n",
    "# input3 모델\n",
    "input3 = Input(shape=(8,))\n",
    "x3 = layers.Dense(128, activation='relu')(input3)\n",
    "x3 = layers.BatchNormalization()(x3)\n",
    "\n",
    "x3 = layers.Dense(16, activation='relu')(x3)\n",
    "x3 = layers.BatchNormalization()(x3)\n",
    "\n",
    "x3 = layers.Dense(16, activation='relu')(x3)\n",
    "x3 = layers.BatchNormalization()(x3)\n",
    "\n",
    "\n",
    "# 직렬 Concatenate\n",
    "combined = layers.Concatenate()([x1, x2, x3])\n",
    "\n",
    "# Fully Connected 층\n",
    "fc_output = layers.Dense(8, activation='relu')(combined)\n",
    "fc_output = layers.BatchNormalization()(fc_output)\n",
    "final_output = layers.Dense(2, activation=None)(fc_output)\n",
    "\n",
    "model = Model(inputs=[input1, input2, input3], outputs=final_output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "right_images_train = np.array(right_images_train)\n",
    "left_images_train = np.array(left_images_train)\n",
    "landmark_train = np.array(landmark_train)\n",
    "labels_train = np.array(labels_train)\n",
    "\n",
    "right_images_test = np.array(right_images_test)\n",
    "left_images_test = np.array(left_images_test)\n",
    "landmark_test = np.array(landmark_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.016)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_logarithmic_error', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    [right_images_train, left_images_train, landmark_train],  # 입력 데이터 리스트\n",
    "    labels_train,                       # 레이블\n",
    "    epochs=40,                                # 에포크 수\n",
    "    batch_size=1,                          # 배치 사이즈\n",
    "    validation_data=([right_images_test, left_images_test, landmark_test], labels_test),  # 검증 데이터와 레이블\n",
    "    verbose=2                                \n",
    ")\n",
    "\n",
    "# 모델 평가\n",
    "loss, mse_metric = model.evaluate([right_images_test, left_images_test, landmark_test], labels_test, verbose=0)\n",
    "print(f'Test Loss (MSLE): {loss}')\n",
    "print(f'Test MSE (metric): {mse_metric}')\n",
    "\n",
    "# 예측\n",
    "predictions = model.predict([right_images_test, left_images_test, landmark_test])\n",
    "\n",
    "# 평가 지표 계산\n",
    "mse = mean_squared_error(labels_test, predictions)\n",
    "mae = mean_absolute_error(labels_test, predictions)\n",
    "r2 = r2_score(labels_test, predictions)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R² Score: {r2}')\n",
    "\n",
    "# 오차 계산\n",
    "errors = labels_test - predictions\n",
    "\n",
    "# 예측 값, 실제 값 및 오차 출력 (예시로 첫 5개 데이터만 출력)\n",
    "for i in range(5):  # 예시로 첫 5개 데이터만 출력\n",
    "    print(f'Actual Value:\\n{labels_test[i]}')\n",
    "    print(f'Predicted Value:\\n{predictions[i]}')\n",
    "    print(f'Error:\\n{errors[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b44c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
